{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda install -c conda-forge pandoc\n",
    "\n",
    "using tdm kernel\n",
    "\n",
    "The initial data is used by using two script:\n",
    "- download_expand_tex_from_arxiv.sh : connect to archive and download article in zip then\n",
    "                         use a perl code base to merge the project into a single .tex file\n",
    "- tex_to_txt.sh : covert the final .tex file into a plain .txt file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfa5c7f4-8125-4f01-8710-4e7a62b973a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import os, ipdb, re\n",
    "import random, evaluate\n",
    "import string\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from datasets import DatasetDict, Dataset, load_dataset\n",
    "import wandb\n",
    "import ast\n",
    "import re, os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger('my_logger')\n",
    "logger.setLevel(logging.ERROR)  # Set the logging level\n",
    "\n",
    "# Create a file handler that logs even debug messages\n",
    "fh = logging.FileHandler('dataset_creation_logs.log')\n",
    "fh.setLevel(logging.ERROR)\n",
    "\n",
    "# Create a formatter and set it for the handler\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(fh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f6cdd-c817-4243-91ca-3a19f64d0bf8",
   "metadata": {},
   "source": [
    "## Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dffad128-2a34-4942-b642-e44a7ed1aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ = [\"2105.02723v1\",\"2104.06378v1\",\"2104.04946v1\",\"1912.03330v1\", \"1912.02738v4\",\"1912.01326v3\", \"1912.00998v2\"]\n",
    "latex = f\"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/sample/{id_[0]}.tex\"\n",
    "# latex = \"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/1312.6114v10.tex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "993bce4f-c010-4263-8820-655f7b7acc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_tdms_context(latex_file, output_folder):\n",
    "    \n",
    "    if len(latex_file.rsplit(\"/\",1)) != 2:\n",
    "        return \n",
    "    \n",
    "    base_source, filename = latex_file.rsplit(\"/\",1)\n",
    "\n",
    "    if len(filename.rsplit(\".\",1)) != 2:\n",
    "        return \n",
    "    \n",
    "    file_id, file_ext = filename.rsplit(\".\",1)\n",
    "    \n",
    "    \n",
    "    # Read the input LaTeX file\n",
    "    with open(latex_file, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # # Define the pattern to match sections to be removed\n",
    "    # # This pattern looks for the string \\section{Introduction} or \\section{Experiment setup}\n",
    "    # # followed by any content until the next occurrence of \\section or the end of the file\n",
    "    # pattern = re.compile(\n",
    "    #     r'\\\\section\\{Introduction\\}.*?(?=\\\\section|\\Z)|'\n",
    "    #     r'\\\\section\\{Related work\\}.*?(?=\\\\section|\\Z)|'\n",
    "    #     r'\\\\section\\{Experiment setup\\}.*?(?=\\\\section|\\Z)',\n",
    "    #     re.DOTALL\n",
    "    # )\n",
    "\n",
    "    # # Define the pattern to match sections to be removed\n",
    "    # # This pattern looks for the string \\section, followed by any number of characters,\n",
    "    # # followed by either 'Introduction' or 'Experiment setup', followed by any characters\n",
    "    # # until the next occurrence of \\section or the end of the file.\n",
    "    # # \\s* matches any whitespace characters, and [^}]* matches any character except '}'\n",
    "    # pattern = re.compile(\n",
    "    #     r'\\\\section\\*?\\s*\\{[^}]*\\b(Introduction(s?)|Related work(s?)|Future work(s?)|Background(s?)|Discussion(s?)|Methodology|Appendix|Supplementary|Supplemental)\\b[^}]*\\}.*?(?=\\\\section|\\\\end\\{document\\}|\\\\bibliography|\\Z)',\n",
    "    #     # r'\\\\section\\s*\\{[^}]*\\b(Introduction|Related work|Future work)\\b[^}]*\\}.*?(?=\\\\section|\\Z)',\n",
    "    #     re.DOTALL | re.IGNORECASE\n",
    "    # )\n",
    "    \n",
    "\n",
    "    pattern = re.compile(\n",
    "        r'''\n",
    "        (                             # Start capturing group\n",
    "            \\\\section                 # Match \\section\n",
    "            \\*?                       # Match optional *\n",
    "            \\s*                       # Match optional whitespace\n",
    "            \\{                        # Match {\n",
    "            (?!                       # Start negative lookahead\n",
    "                Result(s?)               # Negative lookahead for Results\n",
    "                |                     # Or\n",
    "                Experimentation(s?)       # Negative lookahead for Experimentation\n",
    "                |\n",
    "                Experiment(s?)\n",
    "                |\n",
    "                Conclusion\n",
    "            )                         # End negative lookahead\n",
    "            [^}]*                     # Match any characters except }\n",
    "            \\}                        # Match }\n",
    "            .*?                       # Match any characters (non-greedy)\n",
    "            (?=\\\\section|\\\\end\\{document\\}|\\\\bibliography|\\Z)          # Positive lookahead for next \\section, \\end{document}, \\bibliography or end of string\n",
    "        )                             # End capturing group\n",
    "        ''',\n",
    "        re.DOTALL | re.IGNORECASE | re.VERBOSE\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Remove the matched content\n",
    "    content_new = re.sub(pattern, '', content)\n",
    "\n",
    "    if not os.path.exists(f\"{output_folder}\"):\n",
    "        os.makedirs(f\"{output_folder}\")\n",
    "        \n",
    "    # if os.path.exists(f\"{base_source}/edits/{file_id}_edit.{file_ext}\"):\n",
    "    #     os.remove(f\"{base_source}/edits/{file_id}_edit.{file_ext}\")\n",
    "            \n",
    "    # Write the modified content back to the file\n",
    "    with open(f\"{output_folder}/{file_id}_summarised.{file_ext}\", 'w', encoding='utf-8', errors='ignore') as file:\n",
    "        file.write(content_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "351a86b8-d14a-4b4f-a8d3-ca07ca2f3d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4737/4737 [03:55<00:00, 20.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# source_folder = \"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_tex\"\n",
    "source_folder = \"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_no_leaderboard_links_tex_first_5000\"\n",
    "\n",
    "for file_id in tqdm(os.listdir(f\"{source_folder}\")):\n",
    "    latex_file = f\"{source_folder}/{file_id}\"\n",
    "    potential_tdms_context(latex_file, output_folder=\"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_no_leaderboard_summarised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandoc_latex_to_text(latex_file, output_folder):\n",
    "    # Output a plain text file given a valid .tex file. \n",
    "    \n",
    "    file_ID = latex_file.rsplit(\"/\")[-1].rsplit(\".\", 1)[0]\n",
    "    \n",
    "    if not os.path.exists(f\"{output_folder}\"):\n",
    "        os.makedirs(f\"{output_folder}\")\n",
    "    \n",
    "    # logger.warning(f\"Processing {file_ID}\")\n",
    "    # Construct the command\n",
    "    command = [\n",
    "        \"pandoc\",\n",
    "        \"--to=plain\",\n",
    "        \"--template=../data_proccess/template.plain\",\n",
    "        \"--wrap=none\",\n",
    "        f\"{latex_file}\",\n",
    "        \"-o\",\n",
    "        f\"{output_folder}/{file_ID}.txt\",\n",
    "        \"--quiet\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        # print(f\"Processing file : {file_ID}\")\n",
    "        result = subprocess.run(command, stderr=subprocess.PIPE, text=True, timeout=120)\n",
    "        result.check_returncode()  # This will raise CalledProcessError if the command failed\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        error_message = e.stderr\n",
    "        # print(f\"File {latex_file} failed with an error: {error_message}\")\n",
    "        logger.error(f\"File {latex_file} failed with an error: {error_message}\")\n",
    "    except subprocess.TimeoutExpired as e:\n",
    "        # Handle the timeout case\n",
    "        logger.error(f\"File {latex_file} processing timed out after 2 minutes\")\n",
    "    \n",
    "\n",
    "# pandoc --to=plain --template=template.plain --wrap=none \"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_tex/{id_[i]}.tex\" -o \"$arxiv_txt_dir/${file_ID}.txt\" --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pandoc --to=plain --template=../data_proccess/template.plain --wrap=none \"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_tex/1911.08670v2.tex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c4a37-2860-4f7a-8385-de857bcfce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1\n",
    "\n",
    "# Example usage\n",
    "id_ = [\"2105.01288v1\",\"2105.01601v1\",\"2105.01883v1\", \"2105.02184v1\", \"1911.08670v2\"]\n",
    "# latex_file = f\"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/sample/{id_[i]}.tex\"\n",
    "latex_file = f\"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_tex/{id_[i]}.tex\"\n",
    "\n",
    "pandoc_latex_to_text(latex_file, output_folder=\"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ = [\"2105.01288v1_edit\",\"2105.01601v1_edit\",\"2105.01883v1_edit\", \"2105.02184v1_edit\", \"1611.01731v2_summarised\"]\n",
    "latex_file = f\"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/sample/edits/{id_[i]}.tex\"\n",
    "\n",
    "\n",
    "pandoc_latex_to_text(latex_file, \n",
    "                     output_folder=\"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/sample/edits\")\n",
    "\n",
    "# try:\n",
    "#     # Code that might raise an exception\n",
    "#     pandoc_latex_to_text(latex_file, output_folder=\"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/sample/edits\")\n",
    "# except Exception as e:\n",
    "#     # Code that runs if the exception occurs\n",
    "#     print(f\"File {latex_file} filed :(\")\n",
    "#     print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run for all .tex files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "120/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4657/4657 [31:08<00:00,  2.49it/s]   \n"
     ]
    }
   ],
   "source": [
    "source_tex = \"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_tex_summarised\"\n",
    "for latex_file in tqdm(os.listdir(f\"{source_tex}\")):\n",
    "# for latex_file in os.listdir(f\"{source_tex}\"):\n",
    "    pandoc_latex_to_text(f\"{source_tex}/{latex_file}\", \n",
    "                         output_folder=\"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_txt_summarised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4737/4737 [14:13<00:00,  5.55it/s]  \n"
     ]
    }
   ],
   "source": [
    "source_tex = \"//nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_no_leaderboard_summarised\"\n",
    "for latex_file in tqdm(os.listdir(f\"{source_tex}\")):\n",
    "# for latex_file in os.listdir(f\"{source_tex}\"):\n",
    "    pandoc_latex_to_text(f\"{source_tex}/{latex_file}\", \n",
    "                         output_folder=\"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_no_leaderboard_txt_summarised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90362e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d7681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485df5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for file in os.listdir(\"../data_proccess/arxiv_txt_summarised/\"):\n",
    "    file_path = \"../data_proccess/arxiv_txt_summarised\"\n",
    "\n",
    "    with open(f\"{file_path}/{file}\", 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    if len(content.split(\"\\n\\n\")) < 5 :\n",
    "    # if len(content.split()) <= 300 and len(content.split()) <= 380:\n",
    "    # if len(content.split()) <= 250 :\n",
    "        # print(len(content.split()))\n",
    "        count += 1\n",
    "        \n",
    "    # if 'Title:\\t\\n\\nAbstract:\\t\\n' == content:\n",
    "    #     print(\"delete\")\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a5a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for file in os.listdir(\"../data_proccess/arxiv_txt_summarised/\"):\n",
    "    file_path = \"../data_proccess/arxiv_txt_summarised\"\n",
    "\n",
    "    with open(f\"{file_path}/{file}\", 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    if len(content.split()) >= 50 and len(content.split()) <= 100:\n",
    "        # print(len(content.split()))\n",
    "        count += 1\n",
    "        \n",
    "    # if 'Title:\\t\\n\\nAbstract:\\t\\n' == content:\n",
    "    #     print(\"delete\")\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
