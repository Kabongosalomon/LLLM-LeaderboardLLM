{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMeOslZ9Qxlx",
    "outputId": "dc92a995-ef87-404f-e1da-2a9da7fbb6d6"
   },
   "outputs": [],
   "source": [
    "# !pip install --quiet  datasets #to access squad dataset\n",
    "# !pip install --quiet pyarrow   #to deal with parquet files for saving dataset if required\n",
    "# !pip install --quiet  tqdm     #for progress bars\n",
    "# !pip install --quiet transformers # for t5 model\n",
    "# !pip install --quiet tokenizers  #tokenizers from HuggingFace\n",
    "# !pip install --quiet sentencepiece #subword tokenizer used by T5\n",
    "# !pip install --quiet pytorch-lightning # pytorch wrapper \n",
    "# !pip install --quiet torchtext # text utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contructed random 50% dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datasets import DatasetDict, Dataset, load_from_disk\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "from pprint import pprint\n",
    "import copy, os, json, shutil\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import ipdb, re\n",
    "\n",
    "pd.options.display.max_rows , pd.options.display.max_columns  = 100,100  \n",
    "\n",
    "# Fraction for sample dataframe\n",
    "proportion = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed Leaderboard papers: 295\n",
      "Missed No Leaderboard papers: 918\n"
     ]
    }
   ],
   "source": [
    "arxiv_txt_summarised_dec092023 = os.listdir(\"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_txt_summarised_dec092023\")\n",
    "arxiv_txt_dec092023 = os.listdir(\"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_txt_dec092023\")\n",
    "\n",
    "missed_lb_papers = []\n",
    "for paper in arxiv_txt_summarised_dec092023:\n",
    "    paper_id = paper.rsplit(\"_\",1)[0]\n",
    "    if f\"{paper_id}.txt\" in arxiv_txt_dec092023:\n",
    "        # paper_id_full =  paper.rsplit(\".\",1)[0]\n",
    "        pass\n",
    "    else:\n",
    "        missed_lb_papers.append(paper_id)\n",
    "\n",
    "\n",
    "print(f\"Missed Leaderboard papers: {len(missed_lb_papers)}\")\n",
    "\n",
    "arxiv_txt_summarised_dec092023 = os.listdir(\"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_no_leaderboard_txt_25_000_summarised_dec092023\")\n",
    "arxiv_txt_dec092023 = os.listdir(\"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_no_leaderboard_txt_25_000_dec092023\")\n",
    "\n",
    "missed_no_lb_papers = []\n",
    "for paper in arxiv_txt_summarised_dec092023:\n",
    "    paper_id = paper.rsplit(\"_\",1)[0]\n",
    "    if f\"{paper_id}.txt\" in arxiv_txt_dec092023:\n",
    "        # paper_id_full =  paper.rsplit(\".\",1)[0]\n",
    "        pass\n",
    "    else:\n",
    "        missed_no_lb_papers.append(paper_id)\n",
    "\n",
    "\n",
    "print(f\"Missed No Leaderboard papers: {len(missed_no_lb_papers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295/295 [00:00<00:00, 3469.79it/s]\n",
      "100%|██████████| 918/918 [00:07<00:00, 125.78it/s]\n"
     ]
    }
   ],
   "source": [
    "path_leaderboard_tex = \"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_tex_dec092023\"\n",
    "target_lb_folder = \"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/retry_tex_lb\"\n",
    "\n",
    "for latex_paper in tqdm(missed_lb_papers):\n",
    "    if not os.path.exists(f\"{target_lb_folder}/{latex_paper}.tex\"):\n",
    "        shutil.copyfile(f\"{path_leaderboard_tex}/{latex_paper}.tex\", f\"{target_lb_folder}/{latex_paper}.tex\")\n",
    "    \n",
    "path_no_leaderboard_tex = \"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_no_leaderboard_tex_25_000\"\n",
    "target_no_lb_folder = \"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/retry_tex_no_lb\"\n",
    "\n",
    "for latex_paper in tqdm(missed_no_lb_papers):\n",
    "    if not os.path.exists(f\"{target_no_lb_folder}/{latex_paper}.tex\"):\n",
    "        shutil.copyfile(f\"{path_no_leaderboard_tex}/{latex_paper}.tex\", f\"{target_no_lb_folder}/{latex_paper}.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1900.56s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM\n"
     ]
    }
   ],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1879.32s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM\n"
     ]
    }
   ],
   "source": [
    "# %cd ../data_proccess/\n",
    "!pwd\n",
    "# !bash /nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/tex_to_txt.sh /nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/retry_tex_lb /nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_txt_dec092023\n",
    "# !bash tex_to_txt.sh retry_tex_lb arxiv_txt_dec092023\n",
    "# !bash tex_to_txt.sh retry_tex_no_lb arxiv_no_leaderboard_txt_25_000_dec092023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_tdms_f1_50_percent.to_parquet('../data/df_train_tdms_augmented_summarized_with_id_f1_50_percent.parquet')\n",
    "# df_dev_tdms_f1_50_percent.to_parquet('../data/df_dev_tdms_augmented_summarized_with_id_f1_50_percent.parquet')\n",
    "# df_zeroshot_tdms_f1_50_percent.to_parquet('../data/df_zeroshot_tdms_augmented_summarized_with_id_f1_50_percent.parquet')\n",
    "\n",
    "# df_train_tdms_f2_50_percent.to_parquet('../data/df_train_tdms_augmented_summarized_with_id_f2_50_percent.parquet')\n",
    "# df_dev_tdms_f2_50_percent.to_parquet('../data/df_dev_tdms_augmented_summarized_with_id_f2_50_percent.parquet')\n",
    "\n",
    "# dataset = DatasetDict({\n",
    "#     'fold1': DatasetDict({\n",
    "#         \"train\": Dataset.from_parquet('../data/df_train_tdms_augmented_summarized_with_id_f1_50_percent.parquet'),\n",
    "#         \"validation\": Dataset.from_parquet('../data/df_dev_tdms_augmented_summarized_with_id_f1_50_percent.parquet'),\n",
    "#         \"zeroshot\": Dataset.from_parquet('../data/df_zeroshot_tdms_augmented_summarized_with_id_f1_50_percent.parquet')\n",
    "#     }),\n",
    "#     'fold2': DatasetDict({\n",
    "#         \"train\": Dataset.from_parquet('../data/df_train_tdms_augmented_summarized_with_id_f2_50_percent.parquet'),\n",
    "#         \"validation\": Dataset.from_parquet('../data/df_dev_tdms_augmented_summarized_with_id_f2_50_percent.parquet')\n",
    "#     })\n",
    "# })\n",
    "\n",
    "# print(dataset)\n",
    "\n",
    "# dataset.save_to_disk(\"../data/LLLM_AUGMENTED_SUMMARIZED_ZEROSHOT_TDMS_50_PERCENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>template</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005.10469v1.pdf</td>\n",
       "      <td>Title:\\tASAPP-ASR: Multistream CNN and Self-At...</td>\n",
       "      <td>[{'LEADERBOARD': {'Task': 'Speech Recognition'...</td>\n",
       "      <td>squad_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1801.07606v1.pdf</td>\n",
       "      <td>Title:\\tDeeper Insights into Graph Convolution...</td>\n",
       "      <td>[{'LEADERBOARD': {'Task': 'Node Classification...</td>\n",
       "      <td>squad_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1706.03762v7.pdf</td>\n",
       "      <td>Title:\\tAttention Is All You Need\\n\\nAbstract:...</td>\n",
       "      <td>[{'LEADERBOARD': {'Task': 'Machine Translation...</td>\n",
       "      <td>squad_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2301.13808v3.pdf</td>\n",
       "      <td>Title:\\tLarge Language Models are Versatile De...</td>\n",
       "      <td>[{'LEADERBOARD': {'Task': 'Semantic Parsing', ...</td>\n",
       "      <td>squad_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007.12749v2.pdf</td>\n",
       "      <td>Title:\\tHard negative examples are hard, but u...</td>\n",
       "      <td>[{'LEADERBOARD': {'Task': 'Metric Learning', '...</td>\n",
       "      <td>squad_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                             prompt  \\\n",
       "0  2005.10469v1.pdf  Title:\\tASAPP-ASR: Multistream CNN and Self-At...   \n",
       "1  1801.07606v1.pdf  Title:\\tDeeper Insights into Graph Convolution...   \n",
       "2  1706.03762v7.pdf  Title:\\tAttention Is All You Need\\n\\nAbstract:...   \n",
       "3  2301.13808v3.pdf  Title:\\tLarge Language Models are Versatile De...   \n",
       "4  2007.12749v2.pdf  Title:\\tHard negative examples are hard, but u...   \n",
       "\n",
       "                                              answer template  \n",
       "0  [{'LEADERBOARD': {'Task': 'Speech Recognition'...  squad_1  \n",
       "1  [{'LEADERBOARD': {'Task': 'Node Classification...  squad_1  \n",
       "2  [{'LEADERBOARD': {'Task': 'Machine Translation...  squad_1  \n",
       "3  [{'LEADERBOARD': {'Task': 'Semantic Parsing', ...  squad_1  \n",
       "4  [{'LEADERBOARD': {'Task': 'Metric Learning', '...  squad_1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Long txt \n",
    "base_txt_path = \"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess\"\n",
    "# \"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/arxiv_no_leaderboard_txt_25_000_dec092023\"\n",
    "\n",
    "# DOCTEAT\n",
    "docteat_path = \"\"\n",
    "\n",
    "# AUGMENTED\n",
    "train_f1_data_path = \"../data/df_train_tdms_augmented_summarized_with_id_f1_50_percent.parquet\"\n",
    "dev_f1_data_path = \"../data/df_dev_tdms_augmented_summarized_with_id_f1_50_percent.parquet\"\n",
    "zeroshot_f1_data_path = \"../data/df_zeroshot_tdms_augmented_summarized_with_id_f1_50_percent.parquet\"\n",
    "\n",
    "train_f2_data_path = \"../data/df_train_tdms_augmented_summarized_with_id_f2_50_percent.parquet\"\n",
    "dev_f2_data_path = \"../data/df_dev_tdms_augmented_summarized_with_id_f2_50_percent.parquet\"\n",
    "\n",
    "\n",
    "df_train_tdms_f1 = pd.read_parquet(train_f1_data_path)\n",
    "df_dev_tdms_f1 = pd.read_parquet(dev_f1_data_path)\n",
    "df_zeroshot_tdms_f1 = pd.read_parquet(zeroshot_f1_data_path)\n",
    "\n",
    "df_train_tdms_f2 = pd.read_parquet(train_f2_data_path)\n",
    "df_dev_tdms_f2 = pd.read_parquet(dev_f2_data_path)\n",
    "\n",
    "# df_docteat_full = pd.read_csv(docteat_path)\n",
    "\n",
    "\n",
    "df_train_tdms_f1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>template</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>1909.03329v2.pdf</td>\n",
       "      <td>Context: Title:\\tLAMOL: LAnguage MOdeling for\\...</td>\n",
       "      <td>[{'LEADERBOARD': {'Task': 'Continual Learning'...</td>\n",
       "      <td>drop_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>1710.11252v2.pdf</td>\n",
       "      <td>Context: Title:\\tStochastic Variational Video ...</td>\n",
       "      <td>[{'LEADERBOARD': {'Task': 'Video Generation', ...</td>\n",
       "      <td>drop_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>1904.09658v4.pdf</td>\n",
       "      <td>Context: Title:\\tProbabilistic Face Embeddings...</td>\n",
       "      <td>[{'LEADERBOARD': {'Task': 'Face Verification',...</td>\n",
       "      <td>drop_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>1102.2094.pdf</td>\n",
       "      <td>Context: Title:\\tGlobal Scheduling of Multi-Mo...</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>drop_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>1412.4726.pdf</td>\n",
       "      <td>Context: Title:\\tExperimental economics for we...</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>drop_7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                             prompt  \\\n",
       "8995  1909.03329v2.pdf  Context: Title:\\tLAMOL: LAnguage MOdeling for\\...   \n",
       "8996  1710.11252v2.pdf  Context: Title:\\tStochastic Variational Video ...   \n",
       "8997  1904.09658v4.pdf  Context: Title:\\tProbabilistic Face Embeddings...   \n",
       "8998     1102.2094.pdf  Context: Title:\\tGlobal Scheduling of Multi-Mo...   \n",
       "8999     1412.4726.pdf  Context: Title:\\tExperimental economics for we...   \n",
       "\n",
       "                                                 answer template  \n",
       "8995  [{'LEADERBOARD': {'Task': 'Continual Learning'...   drop_7  \n",
       "8996  [{'LEADERBOARD': {'Task': 'Video Generation', ...   drop_7  \n",
       "8997  [{'LEADERBOARD': {'Task': 'Face Verification',...   drop_7  \n",
       "8998                                       unanswerable   drop_7  \n",
       "8999                                       unanswerable   drop_7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zeroshot_tdms_f1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please answer a question about  this article. If the question is unanswerable, say \"unanswerable\".'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Please answer a question about Answer this question:  this article. If the question is Answer this question: unanswerable, say \"unanswerable\".'.replace('Answer this question: ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_template(txts):\n",
    "    \n",
    "    # Filter rows where the 'text' column contains the given substring\n",
    "    # substring_to_match_squad_1 = re.escape('Please answer a question about this article. If the question is unanswerable, say \"unanswerable\".')\n",
    "    \n",
    "    substring_to_match_squad_1 = 'Please answer a question about this article. If the question is unanswerable, say \"unanswerable\".'\n",
    "    substring_to_match_squad_2 = 'Read this and answer the question. If the question is unanswerable, say \\\"unanswerable\\\".'\n",
    "    substring_to_match_squad_3 = '(If the question is unanswerable, say \\\"unanswerable\\\"'\n",
    "    substring_to_match_squad_4 = 'Try to answer this question if possible (otherwise reply \\\"unanswerable\\\")'\n",
    "    substring_to_match_squad_5 = 'If it is possible to answer this question, answer it for me (else, reply \\\"unanswerable\\\"):'\n",
    "    substring_to_match_squad_6 = 'Answer this question, if possible (if impossible, reply \\\"unanswerable\\\"):'\n",
    "    substring_to_match_squad_7 = 'What is the answer? (If it cannot be answered, return \\\"unanswerable\\\")'\n",
    "    substring_to_match_squad_8 = 'Now answer this question, if there is an answer (If it cannot be answered, return \\\"unanswerable\\\"):'\n",
    "\n",
    "    substring_to_match_drop_1 = 'Answer based on context:'\n",
    "    substring_to_match_drop_2 = 'Answer this question based on the article:'\n",
    "    # substring_to_match_drop_3 = ''\n",
    "    substring_to_match_drop_4 = 'Answer this question: '\n",
    "    substring_to_match_drop_5 = 'Read this article and answer this question'\n",
    "    substring_to_match_drop_6 = 'Based on the above article, answer a question.'\n",
    "    substring_to_match_drop_7 = 'Context: '\n",
    "\n",
    "    template = \"squad_1\" if substring_to_match_squad_1 in txts else \\\n",
    "            \"squad_2\" if substring_to_match_squad_2 in txts else \\\n",
    "            \"squad_3\" if substring_to_match_squad_3 in txts else \\\n",
    "            \"squad_4\" if substring_to_match_squad_4 in txts else \\\n",
    "            \"squad_5\" if substring_to_match_squad_5 in txts else \\\n",
    "            \"squad_6\" if substring_to_match_squad_6 in txts else \\\n",
    "            \"squad_7\" if substring_to_match_squad_7 in txts else \\\n",
    "            \"squad_8\" if substring_to_match_squad_8 in txts else \\\n",
    "            \"drop_1\" if substring_to_match_drop_1 in txts else \\\n",
    "            \"drop_2\" if substring_to_match_drop_2 in txts else \\\n",
    "            \"drop_4\" if substring_to_match_drop_4 in txts else \\\n",
    "            \"drop_5\" if substring_to_match_drop_5 in txts else \\\n",
    "            \"drop_6\" if substring_to_match_drop_6 in txts else \\\n",
    "            \"drop_7\" if substring_to_match_drop_7 in txts else \"drop_3\"\n",
    "            \n",
    "    return template\n",
    "\n",
    "def add_template_df(df):\n",
    "        # Filter rows where the 'text' column contains the given substring\n",
    "        # substring_to_match_squad_1 = re.escape('Please answer a question about this article. If the question is unanswerable, say \"unanswerable\".')\n",
    "        substring_to_match_squad_1 = 'Please answer a question about this article. If the question is unanswerable, say \"unanswerable\".'\n",
    "        substring_to_match_squad_2 = 'Read this and answer the question. If the question is unanswerable, say \\\"unanswerable\\\".'\n",
    "        substring_to_match_squad_3 = '(If the question is unanswerable, say \\\"unanswerable\\\"'\n",
    "        substring_to_match_squad_4 = 'Try to answer this question if possible (otherwise reply \\\"unanswerable\\\")'\n",
    "        substring_to_match_squad_5 = 'If it is possible to answer this question, answer it for me (else, reply \\\"unanswerable\\\"):'\n",
    "        substring_to_match_squad_6 = 'Answer this question, if possible (if impossible, reply \\\"unanswerable\\\"):'\n",
    "        substring_to_match_squad_7 = 'What is the answer? (If it cannot be answered, return \\\"unanswerable\\\")'\n",
    "        substring_to_match_squad_8 = 'Now answer this question, if there is an answer (If it cannot be answered, return \\\"unanswerable\\\"):'\n",
    "\n",
    "        substring_to_match_drop_1 = 'Answer based on context:'\n",
    "        substring_to_match_drop_2 = 'Answer this question based on the article:'\n",
    "        # substring_to_match_drop_3 = ''\n",
    "        substring_to_match_drop_4 = 'Answer this question: '\n",
    "        substring_to_match_drop_5 = 'Read this article and answer this question'\n",
    "        substring_to_match_drop_6 = 'Based on the above article, answer a question.'\n",
    "        substring_to_match_drop_7 = 'Context: '\n",
    "\n",
    "        # TDMS\n",
    "        df['template'] = df['prompt'].apply(\n",
    "        lambda x : \"squad_1\" if substring_to_match_squad_1 in x else \\\n",
    "                \"squad_2\" if substring_to_match_squad_2 in x else \\\n",
    "                \"squad_3\" if substring_to_match_squad_3 in x else \\\n",
    "                \"squad_4\" if substring_to_match_squad_4 in x else \\\n",
    "                \"squad_5\" if substring_to_match_squad_5 in x else \\\n",
    "                \"squad_6\" if substring_to_match_squad_6 in x else \\\n",
    "                \"squad_7\" if substring_to_match_squad_7 in x else \\\n",
    "                \"squad_8\" if substring_to_match_squad_8 in x else \\\n",
    "                \"drop_1\" if substring_to_match_drop_1 in x else \\\n",
    "                \"drop_2\" if substring_to_match_drop_2 in x else \\\n",
    "                \"drop_4\" if substring_to_match_drop_4 in x else \\\n",
    "                \"drop_5\" if substring_to_match_drop_5 in x else \\\n",
    "                \"drop_6\" if substring_to_match_drop_6 in x else \\\n",
    "                \"drop_7\" if substring_to_match_drop_7 in x else \"drop_3\"\n",
    "                )\n",
    "        return df\n",
    "\n",
    "def df_stats(df):\n",
    "  df = add_template_df(df)\n",
    "  display(df.describe())\n",
    "  df[\"prompt lenght\"] = df.prompt.apply(lambda x: len(x.split()))\n",
    "  display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>template</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>92910</td>\n",
       "      <td>92910</td>\n",
       "      <td>92910</td>\n",
       "      <td>92910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>12388</td>\n",
       "      <td>92545</td>\n",
       "      <td>7976</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1704.06326v2.pdf</td>\n",
       "      <td>Title:\\t\\n\\nAbstract:\\t\\n\\n[image]\\n\\nTry to a...</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>drop_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>33072</td>\n",
       "      <td>6198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                             prompt  \\\n",
       "count              92910                                              92910   \n",
       "unique             12388                                              92545   \n",
       "top     1704.06326v2.pdf  Title:\\t\\n\\nAbstract:\\t\\n\\n[image]\\n\\nTry to a...   \n",
       "freq                  14                                                 17   \n",
       "\n",
       "              answer template  \n",
       "count          92910    92910  \n",
       "unique          7976       15  \n",
       "top     unanswerable   drop_7  \n",
       "freq           33072     6198  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt lenght</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>92910.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1586.278366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1759.270945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>555.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1490.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>127689.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prompt lenght\n",
       "count   92910.000000\n",
       "mean     1586.278366\n",
       "std      1759.270945\n",
       "min        27.000000\n",
       "25%       555.000000\n",
       "50%      1490.000000\n",
       "75%      2185.000000\n",
       "max    127689.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_stats(df_train_tdms_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1912.09745v1', 'pdf']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_tdms_f1.iloc[200]['id'].rsplit(\".\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 17/92910 [00:00<10:40, 144.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92910/92910 [20:12<00:00, 76.61it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed file parsing count: 4438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_pandas_new_context(df, data_path):\n",
    "\n",
    "  ''' Create a Pandas Dataframe from pandas.\n",
    "  Params:\n",
    "        answer_threshold: Only consider those Question Answer pairs where the Answer is short.\n",
    "  '''\n",
    "  count_index = 0\n",
    "  result_df  = pd.DataFrame(columns = ['id', 'prompt', 'answer'])   \n",
    "  \n",
    "  q_types = [\n",
    "    {\"q\": \"What are the values for the following properties to construct a Leaderboard for the model introduced in this article: task, dataset, metric, and score?\", \"a_key\": \"answer\"},\n",
    "    ]\n",
    "  \n",
    "  records = df.to_dict(\"records\")\n",
    "  missed_parsing = []\n",
    "  \n",
    "  for i, row in tqdm(enumerate(records), total = len(records)):        \n",
    "      for q_type in q_types:\n",
    "        \n",
    "        template = find_template(row[\"prompt\"])\n",
    "        file_id = row[\"id\"].rsplit(\".\", 1)[0]\n",
    "        try:\n",
    "          with open(f'{data_path}/arxiv_txt_dec092023/{file_id}.txt', 'r') as file:\n",
    "            # Read the file\n",
    "            new_context = file.read()\n",
    "        \n",
    "        except :\n",
    "          try:\n",
    "            with open(f'{data_path}/arxiv_no_leaderboard_txt_25_000_dec092023/{file_id}.txt', 'r') as file:\n",
    "              # Read the file\n",
    "              new_context = file.read()\n",
    "              \n",
    "          except:\n",
    "            missed_parsing.append(file_id)\n",
    "            continue\n",
    "                \n",
    "        ## Squad_v2 \n",
    "        if template == \"squad_1\":\n",
    "          # prompt = row[\"prompt\"].replace(\n",
    "          #   \"\\nPlease answer a question about this article. If the question is unanswerable, say \\\"unanswerable\\\".\",\n",
    "          #   \"\"\n",
    "          # ).replace(\n",
    "          #   \"What are the values for the following properties to construct a Leaderboard for the model introduced in this article: task, dataset, metric, and score?\",\n",
    "          #   \"\"\n",
    "          # )\n",
    "          \n",
    "          result_df.loc[count_index] = [str(row[\"id\"])] + [f'{new_context}\\n\\nPlease answer a question about this article. If the question is unanswerable, say \\\"unanswerable\\\". {q_type[\"q\"]}'] \\\n",
    "            + [str(row[q_type[\"a_key\"]])]\n",
    "          count_index += 1\n",
    "        \n",
    "        if template == \"squad_2\":\n",
    "          result_df.loc[count_index] = [str(row[\"id\"])] + [f'Read this and answer the question. If the question is unanswerable, say \\\"unanswerable\\\".\\n\\n{new_context}\\n\\n{q_type[\"q\"]}'\n",
    "  ] \\\n",
    "            + [str(row[q_type[\"a_key\"]])] \n",
    "          count_index += 1\n",
    "        \n",
    "        if template == \"squad_3\":\n",
    "          result_df.loc[count_index] = [str(row[\"id\"])] + [f'{new_context}\\n{q_type[\"q\"]} (If the question is unanswerable, say \\\"unanswerable\\\"'] \\\n",
    "            + [str(row[q_type[\"a_key\"]])] \n",
    "          count_index += 1\n",
    "        \n",
    "        if template == \"squad_4\":\n",
    "          result_df.loc[count_index] = [str(row[\"id\"])] + [f'{new_context}\\nTry to answer this question if possible (otherwise reply \\\"unanswerable\\\"): {q_type[\"q\"]}'] \\\n",
    "            + [str(row[q_type[\"a_key\"]])] \n",
    "          count_index += 1\n",
    "        \n",
    "        if template == \"squad_5\":\n",
    "          result_df.loc[count_index] = [str(row[\"id\"])] + [f'{new_context}\\nIf it is possible to answer this question, answer it for me (else, reply \\\"unanswerable\\\"): {q_type[\"q\"]}'] \\\n",
    "            + [str(row[q_type[\"a_key\"]])] \n",
    "          count_index += 1\n",
    "        \n",
    "        if template == \"squad_6\":\n",
    "          result_df.loc[count_index] = [str(row[\"id\"])] + [f'{new_context}\\n\\nAnswer this question, if possible (if impossible, reply \\\"unanswerable\\\"): {q_type[\"q\"]}'] \\\n",
    "            + [str(row[q_type[\"a_key\"]])] \n",
    "          count_index += 1\n",
    "        \n",
    "        if template == \"squad_7\":\n",
    "          result_df.loc[count_index] = [str(row[\"id\"])] + [f'Read this: {new_context}\\n\\n{q_type[\"q\"]}\\nWhat is the answer? (If it cannot be answered, return \\\"unanswerable\\\")'] \\\n",
    "            + [str(row[q_type[\"a_key\"]])] \n",
    "          count_index += 1\n",
    "        \n",
    "        if template == \"squad_8\":\n",
    "          result_df.loc[count_index] = [str(row[\"id\"])] + [f'Read this: {new_context}\\nNow answer this question, if there is an answer (If it cannot be answered, return \\\"unanswerable\\\"): {q_type[\"q\"]}'] \\\n",
    "            + [str(row[q_type[\"a_key\"]])] \n",
    "          count_index += 1\n",
    "        \n",
    "        \n",
    "        # Drop\n",
    "        if template == \"drop_1\":\n",
    "          result_df.loc[count_index] = [str(row[\"id\"])] + [f'Answer based on context:\\n\\n{new_context}\\n\\n{q_type[\"q\"]}'] \\\n",
    "            + [str(row[q_type[\"a_key\"]])] \n",
    "          count_index += 1\n",
    "        \n",
    "        if template == \"drop_2\":\n",
    "          result_df.loc[count_index] = [str(row[\"id\"])] + [f'{new_context}\\n\\nAnswer this question based on the article: {q_type[\"q\"]}'] \\\n",
    "            + [str(row[q_type[\"a_key\"]])] \n",
    "          count_index += 1\n",
    "        \n",
    "        if template == \"drop_3\":\n",
    "          result_df.loc[count_index] = [str(row[\"id\"])] + [f'{new_context}\\n\\n{q_type[\"q\"]}'] \\\n",
    "            + [str(row[q_type[\"a_key\"]])] \n",
    "          count_index += 1\n",
    "        \n",
    "        if template == \"drop_4\":\n",
    "          result_df.loc[count_index] = [str(row[\"id\"])] + [f'{new_context}\\nAnswer this question: {q_type[\"q\"]}'] \\\n",
    "            + [str(row[q_type[\"a_key\"]])] \n",
    "          count_index += 1\n",
    "        \n",
    "        if template == \"drop_5\":\n",
    "          result_df.loc[count_index] = [str(row[\"id\"])] + [f'Read this article and answer this question {new_context}\\n{q_type[\"q\"]}'] \\\n",
    "            + [str(row[q_type[\"a_key\"]])] \n",
    "          count_index += 1\n",
    "        \n",
    "        if template == \"drop_6\":\n",
    "          result_df.loc[count_index] = [str(row[\"id\"])] + [f'{new_context}\\n\\nBased on the above article, answer a question. {q_type[\"q\"]}'] \\\n",
    "            + [str(row[q_type[\"a_key\"]])] \n",
    "          count_index += 1\n",
    "        \n",
    "        if template == \"drop_7\":\n",
    "          result_df.loc[count_index] = [str(row[\"id\"])] + [f'Context: {new_context}\\n\\nQuestion: {q_type[\"q\"]}\\n\\nAnswer:'] \\\n",
    "            + [str(row[q_type[\"a_key\"]])] \n",
    "          count_index += 1\n",
    "  \n",
    "  print(f\"Missed file parsing count: {len(missed_parsing)}\")\n",
    "  return result_df, missed_parsing\n",
    "\n",
    "df_train_tdms_f1_long, missed_parsing = create_pandas_new_context(df_train_tdms_f1, base_txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>template</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>88472</td>\n",
       "      <td>88472</td>\n",
       "      <td>88472</td>\n",
       "      <td>88472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11799</td>\n",
       "      <td>88319</td>\n",
       "      <td>7728</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1704.06326v2.pdf</td>\n",
       "      <td>Read this and answer the question. If the ques...</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>squad_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>30539</td>\n",
       "      <td>5930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                             prompt  \\\n",
       "count              88472                                              88472   \n",
       "unique             11799                                              88319   \n",
       "top     1704.06326v2.pdf  Read this and answer the question. If the ques...   \n",
       "freq                  14                                                  4   \n",
       "\n",
       "              answer template  \n",
       "count          88472    88472  \n",
       "unique          7728       15  \n",
       "top     unanswerable  squad_2  \n",
       "freq           30539     5930  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt lenght</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>88472.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5947.473483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3950.197087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3925.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5277.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7062.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>127689.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prompt lenght\n",
       "count   88472.000000\n",
       "mean     5947.473483\n",
       "std      3950.197087\n",
       "min        26.000000\n",
       "25%      3925.000000\n",
       "50%      5277.000000\n",
       "75%      7062.000000\n",
       "max    127689.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_stats(df_train_tdms_f1_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4438"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missed_parsing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(missed_parsing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0707.3170', '0709.1942', '0709.2016', '0710.0244', '0712.1014',\n",
       "       '0712.1167', '0712.3335', '0801.0882', '0802.0017', '0803.2615',\n",
       "       '0803.4030', '0804.3105', '0805.1386', '0806.3033', '0807.1016',\n",
       "       '0809.0159', '0810.5263', '0811.3140', '0812.2734', '0901.3482',\n",
       "       '0902.0926', '0902.3958', '0903.4130', '0904.2712', '0905.2195',\n",
       "       '0905.4090', '0906.0237', '0907.0403', '0907.3135', '0907.5125',\n",
       "       '0909.1647', '0909.2793', '0910.5744', '0910.5833', '0911.2075',\n",
       "       '0912.0681', '0912.2815', '1001.4493', '1001.5471', '1002.2869',\n",
       "       '1002.4561', '1003.4799', '1003.4812', '1005.5278', '1006.0240',\n",
       "       '1006.3020', '1007.1054', '1007.1632', '1007.3961', '1007.4028',\n",
       "       '1007.4057', '1007.4157', '1007.5095', '1008.1657', '1008.1667',\n",
       "       '1008.3889', '1009.0088', '1009.2858', '1009.3599', '1010.2287',\n",
       "       '1010.2472', '1010.2604', '1010.3976', '1010.4108', '1010.4411',\n",
       "       '1011.0221', '1011.2488', '1011.3594', '1012.1095', '1012.2771',\n",
       "       '1012.3100', '1012.4556', '1101.3960', '1101.4753', '1102.0874',\n",
       "       '1102.2405', '1102.2653', '1102.3676', '1103.4577', '1104.0746',\n",
       "       '1104.3636', '1104.5133', '1105.0103', '1105.0392', '1105.6065',\n",
       "       '1106.0736', '1107.0176', '1107.4724', '1108.2063', '1108.3630',\n",
       "       '1108.4471', '1108.5985', '1109.0784', '1109.1264', '1109.5416',\n",
       "       '1110.0463', '1110.4978', '1110.5832', '1110.6183', '1111.2527',\n",
       "       '1112.0534', '1112.2143', '1112.5000', '1201.3601', '1201.4050',\n",
       "       '1201.4150', '1202.3097', '1202.3497', '1202.3974', '1203.3402',\n",
       "       '1204.2933', '1204.5402', '1204.6170', '1205.3414', '1206.3180',\n",
       "       '1206.6098', '1207.0316', '1207.0418', '1207.2017', '1207.4708v2',\n",
       "       '1208.1476', '1208.5324', '1208.6483', '1209.0679', '1209.2166',\n",
       "       '1209.2890', '1209.5903', '1210.3283', '1210.6390', '1211.4047',\n",
       "       '1211.6193', '1212.1629', '1212.4731', '1212.5003', '1212.5692',\n",
       "       '1301.5075', '1301.5136', '1301.7496', '1301.7517', '1302.5820',\n",
       "       '1303.1279', '1303.5302', '1304.1424', '1304.2641', '1304.3653',\n",
       "       '1304.5498', '1304.6734', '1305.1183', '1305.1744', '1305.3699',\n",
       "       '1306.2267', '1306.4919', '1306.6032', '1307.1204', '1307.4824',\n",
       "       '1307.5612', '1308.0066', '1308.0850v5', '1308.2757', '1308.5858',\n",
       "       '1308.6824', '1309.0392', '1309.0844', '1309.1259', '1309.1981',\n",
       "       '1309.5132', '1309.7881', '1310.0932', '1310.8381', '1311.0602',\n",
       "       '1311.1084', '1312.0193', '1312.0722', '1312.3303', '1312.5172',\n",
       "       '1312.6393', '1312.7430', '1401.2974', '1401.5097', '1401.5951',\n",
       "       '1401.6576', '1401.7002', '1401.7191', '1401.7263', '1401.7594',\n",
       "       '1402.3236', '1402.3401', '1402.3506', '1402.6889', '1403.1065',\n",
       "       '1403.1477', '1403.2009', '1403.3286', '1403.5081', '1404.0082',\n",
       "       '1404.0087', '1404.4754', '1405.0329', '1405.0945', '1405.4034',\n",
       "       '1405.5597', '1406.0017', '1406.0774', '1406.1558', '1406.4249',\n",
       "       '1406.5457', '1407.1140', '1407.2109', '1407.3200', '1407.4425',\n",
       "       '1407.6954', '1408.1312', '1408.1422', '1408.2279', '1408.3967v4',\n",
       "       '1408.6196', '1409.2030', '1409.4639', '1410.2813', '1410.4801',\n",
       "       '1410.8674', '1411.0048', '1411.2873', '1411.2874', '1411.4380',\n",
       "       '1411.5289', '1411.6478', '1412.1885', '1412.2304', '1412.4213',\n",
       "       '1501.00669', '1501.00721', '1501.01721', '1502.00911',\n",
       "       '1502.05501', '1502.06194', '1502.07870', '1503.01363',\n",
       "       '1503.02843', '1503.05423', '1503.06009', '1503.06154',\n",
       "       '1503.07158', '1503.07768', '1503.09052', '1504.00627',\n",
       "       '1504.00766', '1504.03522v1', '1504.04240', '1504.07586',\n",
       "       '1504.07862', '1504.08024', '1504.08265', '1505.03445',\n",
       "       '1505.03540v3', '1505.03883', '1505.05055', '1505.06836',\n",
       "       '1506.04215', '1506.04729', '1506.04862', '1506.05017',\n",
       "       '1506.06497', '1506.06726v1', '1507.00403', '1507.03466',\n",
       "       '1507.04394', '1507.05877', '1507.07049', '1507.08051',\n",
       "       '1508.04839', '1508.07076', '1508.07435', '1509.01337',\n",
       "       '1509.01626v3', '1509.03347', '1509.04206', '1509.06507',\n",
       "       '1509.07029', '1509.07207', '1509.08111', '1510.02181',\n",
       "       '1510.06769', '1510.08271', '1510.08274', '1511.00180',\n",
       "       '1511.00440', '1511.01331', '1511.02043', '1511.02348',\n",
       "       '1511.02751', '1511.03609', '1511.04171', '1511.05453',\n",
       "       '1511.08232', '1511.09394', '1512.00184', '1512.01293',\n",
       "       '1512.04047', '1512.04065v2', '1512.05008', '1512.05306',\n",
       "       '1512.05475', '1512.06488', '1512.07319', '1512.08891',\n",
       "       '1601.02484', '1601.03505', '1601.04294', '1601.05176',\n",
       "       '1601.06759v3', '1601.06939', '1601.07724', '1602.00458',\n",
       "       '1602.03595', '1602.05106', '1602.05170', '1602.07360v4',\n",
       "       '1603.06263', '1603.07168', '1603.07485v2', '1604.00641',\n",
       "       '1604.01183', '1604.01202', '1604.02167', '1604.02971',\n",
       "       '1604.03379', '1604.03540v1', '1604.04295', '1604.04815',\n",
       "       '1604.04978', '1604.07535', '1605.00283', '1605.00284',\n",
       "       '1605.00451', '1605.01319', '1605.04434', '1605.06882',\n",
       "       '1605.06904', '1605.08106', '1605.08935', '1606.00545',\n",
       "       '1606.00704v3', '1608.04236v2', '1609.09869v2', '1611.01722v2',\n",
       "       '1612.04460v2', '1702.00045v1', '1702.05532', '1704.00248v1',\n",
       "       '1705.05414v2', '1705.09912v2', '1706.00531v1', '1707.01083v2',\n",
       "       '1707.03692v1', '1709.09930v1', '1710.03463v1', '1710.10903v3',\n",
       "       '1711.06794v2', '1711.07027v3', '1711.09349v3', '1711.10378v2',\n",
       "       '1802.04289v2', '1802.08352v2', '1804.05685v2', '1805.02410v2',\n",
       "       '1805.06413v1', '1805.06939v2', '1805.09821v1', '1806.01484v2',\n",
       "       '1807.00734v3', '1807.01511v1', '1807.03888v2', '1807.04990v1',\n",
       "       '1808.06876v3', '1809.01354v2', '1809.01682v2', '1809.01696v2',\n",
       "       '1809.04983v1', '1810.05102v2', '1810.06453v3', '1810.12575v1',\n",
       "       '1811.01483v3', '1811.05163v1', '1812.00722v2', '1812.01289v2',\n",
       "       '1812.01855v2', '1901.02860v3', '1901.03416v1', '1901.07752v5',\n",
       "       '1902.00038v2', '1902.01275v2', '1902.10360v1', '1902.11049v2',\n",
       "       '1903.00343v1', '1903.10661v1', '1903.10764v2', '1904.00244v1',\n",
       "       '1904.01608v2', '1904.02199v3', '1904.04232v2', '1904.05868v1',\n",
       "       '1904.09745v2', '1904.12584v1', '1905.04161v1', '1905.07177v1',\n",
       "       '1905.07853v1', '1905.10990v1', '1905.11006v2', '1905.12862v2',\n",
       "       '1906.04129v1', '1906.04943v1', '1906.09453v2', '1907.01166v1',\n",
       "       '1908.01098v1', '1908.07433v1', '1908.10432', '1908.10432v1',\n",
       "       '1909.00015v2', '1909.00997v3', '1909.01203v1', '1910.02677v3',\n",
       "       '1910.04396v1', '1911.03531v1', '1911.06997v2', '1911.09265v2',\n",
       "       '1911.09532v2', '1912.08860v1', '1912.09629v3', '2001.01290v2',\n",
       "       '2002.01132v1', '2002.03283v1', '2003.00517v1', '2003.02953v1',\n",
       "       '2003.03229v5', '2003.10469v4', '2004.00070v1', '2004.02984v2',\n",
       "       '2004.05805v2', '2004.07347v3', '2004.12331v1', '2005.10243v3',\n",
       "       '2006.13807v2', '2007.02454v1', '2007.08426v2', '2007.08426v3',\n",
       "       '2007.09860v1', '2008.07669v2', '2008.09093v1', '2009.00165v2',\n",
       "       '2009.02119v1', '2010.02803v3', '2011.01901v3', '2011.11765v2',\n",
       "       '2011.13244v3', '2011.13456v2', '2011.13922v2', '2011.14141v1',\n",
       "       '2012.15638v2', '2101.07974v4', '2102.06356v2', '2102.08786v1',\n",
       "       '2102.10274v2', '2102.10662v2', '2103.06132v2', '2103.10559v2',\n",
       "       '2103.13915v1', '2104.02745v2', '2104.05845v2', '2104.07540v2',\n",
       "       '2104.07540v3', '2104.07658v2', '2104.10674v1', '2104.12533v2',\n",
       "       '2104.12533v4', '2104.13100v4', '2104.13579v1', '2104.13840v4',\n",
       "       '2105.01899v1', '2105.03889v1', '2105.04512v2', '2106.00933v2',\n",
       "       '2106.02253v2', '2106.03598v1', '2106.07971v2', '2106.11250v1',\n",
       "       '2106.14233v2', '2107.01516v3', '2107.03180v1', '2107.05318v1',\n",
       "       '2108.01553v1', '2108.02607v1', '2108.03348v3', '2108.06208v3',\n",
       "       '2109.03502v1', '2109.04712v2', '2109.04919v2', '2109.07234v2',\n",
       "       '2109.07644v5', '2109.12761v2', '2110.01938v1', '2110.04458v1',\n",
       "       '2110.06865v2', '2110.08151v3', '2110.11291v5', '2111.11567v1',\n",
       "       '2111.13579v4', '2112.01838v2', '2112.02250v2', '2112.05893v1',\n",
       "       '2112.06782v1', '2112.07566v2', '2112.10752v2', '2201.00308v3',\n",
       "       '2201.07436v3', '2201.10271v1', '2202.02794v4', '2202.09671v4',\n",
       "       '2202.11660v1', '2202.11684v2', '2203.02167v1', '2203.10593v1',\n",
       "       '2203.10983v2', '2203.13947v1', '2203.16045v1', '2204.02663v2',\n",
       "       '2204.03645v1', '2204.13496v1', '2205.08473v3', '2205.12755v6',\n",
       "       '2205.13326v5', '2205.15733v1', '2206.00664v1', '2206.08194v2',\n",
       "       '2206.13424v3', '2207.00449v3', '2207.08494v2', '2207.10379v1',\n",
       "       '2207.12576v2', '2207.12691v1', '2209.14988v1', '2210.02849v1',\n",
       "       '2210.05382v2', '2210.05974v3', '2210.06006v3', '2210.07839v4',\n",
       "       '2210.10105v2', '2210.12623v2', '2211.00430v1', '2211.09074v1',\n",
       "       '2211.10950v1', '2211.16285v2', '2212.03038v2', '2212.10561v3',\n",
       "       '2212.12294v2', '2212.13138v1', '2301.11956v4', '2302.00049v3',\n",
       "       '2302.00194v1', '2302.09509v1', '2302.09731v1', '2303.02506v2',\n",
       "       '2303.02575v2', '2303.02693v1', '2303.08774v3', '2303.08906v1',\n",
       "       '2303.11419v2', '2303.14126v1', '2305.08018v2', '2305.09617v1',\n",
       "       '2305.12212v2', '2305.13600v1', '2305.14333v2', '2305.15272v2',\n",
       "       '2305.19872v1', '2306.02430v1', '2307.00407v1', '2307.09756v1',\n",
       "       '2308.09662v3', '2308.12817v2', '2308.12966v3', '2309.00310v1',\n",
       "       '2309.11268v2', '2310.01324v1', '2310.06825v1', '2310.11244v1',\n",
       "       '2310.15941v1', '2310.17421v1', '2311.08355v1'], dtype='<U12')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(missed_parsing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title:\\tASAPP-ASR: Multistream CNN and Self-Attentive SRU\\nfor SOTA Speech Recognition\\n\\nAbstract:\\tIn this paper we present state-of-the-art (SOTA) performance on the LibriSpeech corpus with two novel neural network architectures, a multistream CNN for acoustic modeling and a self-attentive simple recurrent unit (SRU) for language modeling. In the hybrid ASR framework, the multistream CNN acoustic model processes an input of speech frames in multiple parallel pipelines where each stream has a unique dilation rate for diversity. Trained with the SpecAugment data augmentation method, it achieves relative word error rate (WER) improvements of 4% on test-clean and 14% on test-other. We further improve the performance via N-best rescoring using a 24-layer self-attentive SRU language model, achieving WERs of 1.75% on test-clean and 4.46% on test-other.\\n\\nIndex Terms: speech recognition, state-of-the-art, LibriSpeech, multistream CNN, self-attentive SRU\\n\\nExperimental Setup and Results\\n\\nLibriSpeech\\n\\nWe conduct the experiments on the LibriSpeech corpus , which is a collection of approximately 1,000hr read speech (16kHz) from the audio books that are part of the LibriVox project . The training data is split into 3 partitions of 100hrs, 360hrs, and 500hrs while both of the dev and test data are split into ‘clean’ and ‘other’ categories, where each category contains around 5hrs of audio. The corpus provides extra written texts of 800M words[1] for LMs. We normalize them to correct typos as well as spelling consistencies between British and American English. The same normalization is applied to all the text transcripts of the training, dev and test set to be consistent.\\n\\nAcoustic Models and Non-SRU Language Models\\n\\nWe follow the conventional steps to train hybrid GMM/HMM acoustic models using the default Kaldi recipe for LibriSpeech[2], up to a point where a triphone model is trained with speaker-adaptive training (SAT) with feature-space MLLR (fMLLR) to further refine Gaussian mixture parameters . The alignment of this model is used for neural network model training as the reference label. The multistream CNN AM described in Section 2.1 is trained on the total 960hr training set with the LF-MMI loss, decaying learning rates from 10⁻³ to 10⁻⁵ over the span of 6 epochs. The mini-batch size is 64.\\n\\nTo prepare a lexicon, we select the most frequently used 200K words from the 800M word text and add out-of-vocabulary words to the original lexicon provided by the LibriSpeech corpus with the CMU phoneset, resulting in a 203K word list in total. We train a G2P model using the Sequitur tool to generate pronunciations for the out-of-vocabulary words.\\n\\nWe use the PocoLM tooklit to train n-gram LMs by modifying the default recipe for the Switchboard corpus[3]. A 4-gram LM is trained on the 800M word text as well as the entire text transcripts for the 960hr training data containing around 10M words. This LM is pruned to a 3-gram, which is used for the 1st-pass decoding. The 4-gram LM is used for n-gram LM rescoring.\\n\\nThe TDNN-LSTM language model is trained on the aforementioned combined text, totaling 810M words, with the default Kaldi RNNLM recipe for LibriSpeech. We modify the dimension of embedding to 4,096 to increase the representational power of contexts in word sequences.\\n\\nSelf-Attentive SRU Language Models\\n\\nDataset\\n\\nWe construct our dataset for language modeling by combining the normalized corpus of 800M words with the text transcripts from the 960h training data, for a total of about 810M words. All of our self-attentivce SRU language models are trained at the utterance level (i.e., the model does not leverage any context past sentence boundaries), with a maximum sequence length of 275 tokens. We train a new 10K BPE vocabulary for our model. We limit the maximum sequence length only during training, not when computing dev set perplexity or when rescoring utterances from N-best hypotheses by the acoustic model with the TDNN-LSTM LM. We report perplexity numbers on dev-clean and dev-other, which include start and end of sentence tokens for each utterance.\\n\\nModel configuration\\n\\nAll the self-attentive SRU LMs are trained using a hidden dimension of 2,048 and a projected dimension of 512 for the self-attention layer. We use a learning rate of 2\\u2005⋅\\u200510⁻⁴ and no dropout. Optimization is done with the RAdam optimizer\\xa0 using a cosine annealing learning rate schedule. We train SRU models of 12 and 24 layers, slightly varying architectures. For the 12 layer model, we train across 8 Tesla V100 GPUs with a total batch size of 192 for 10 epochs. We use an embedding size of 2,048 and tie the input and output weights. We use single-headed attention in the self-attentive modules. We train the 24 layer model on 8 Quadro RTX 8000 GPUs with a total batch size of 512 for 12 epochs. We use an embedding size of 512, do not tie weights, and use 2 heads in the self-attentive modules.\\n\\n      Model      Layers   # Params    Dev   \\n  ------------- -------- ---------- ------- -------\\n       4-5                           clean   other\\n   Transformer     12       74M      37.7    39.5\\n       SRU         12       77M      36.2    38.3\\n       SRU         24       139M     34.3    36.8\\n\\n  : BPE-level perplexities on dev-clean and dev-other for 12 layer Transformer, 12 layer SRU and 24 layer SRU LMs. We include start and end of sentence tokens on each utterance.\\n\\nResults\\n\\nTable 1 shows the perplexities obtained on the dev sets. With our 12 and 24-layer models, we achieve dev-clean perplexities of 36.2 and 34.3 respectively. In the first third of training we see the most improvement, with combined dev set perplexities at 40 for the 12-layer model and 37 for the 24-layer model.\\n\\nFor a comparison we also train a 12-layer Transformer model on the 10K BPE vocabulary. We use a model dimension of 768, feedforward dimension of 2,048, and 8 attention heads. These parameters were chosen as they result in a network with a comparable number of parameters to the 12-layer SRU model. All other parameters such as weight tying mirror the 12-layer SRU model. A cosine annealing learning rate schedule is used, with a linear warmup for the first 20,000 steps. By adding a self-attentive module between SRU layers, we are able to achieve better perplexity using a comparable number of parameters.\\n\\nAnalysis\\n\\nWe show that our proposed self-attentive SRU not only improves performance over the Transformer architecture but also converges faster. As shown in Figure 1, the 12-layer Transformer model reaches a perplexity of 40 in under 1.2M steps, while it only takes 622K training steps for the SRU model. This results in a 2 times training speedup. In practice this reduced training time by almost 2 days, allowing for faster iteration and greater exploration.\\n\\nAdditionally, we show that the perplexity improvement achieved by the 12-layer SRU model transfers directly to a WER improvement when used for candidate rescoring. In Table 2 we compare WERs when using both the SRU model and Transformer for the final stage of N-best rescoring, fixing N at 100. In all dev and test sets the 12-layer SRU achieves a lower WER than the Transformer model.\\n\\n[]\\n\\nDev perplexity curves of 12-layer SRU and Transformer models. Vertical lines signify when each model reaches a perplexity of 40. Here perplexity is reported on the combination of dev-clean and dev-other.\\n\\n     Rescoring Model       Dev            Test   \\n  ---------------------- ------- ------- ------- -------\\n           2-5            clean   other   clean   other\\n   12-layer Transformer   1.62    4.41    1.96    4.70\\n       12-layer SRU       1.59    4.38    1.93    4.62\\n\\n  : WER (in %) comparison of 12-layer Transformer and 12-layer SRU for N-best rescoring.\\n\\nResults and Analysis\\n\\nTable 3 shows the WER comparison of different experimental setups for the multistream CNN AM and staged rescoring with various LMs. The setup of TDNN-F + 4-gram is a baseline with the TDNN-F acoustic model of the Kaldi Librispeech recipe rescored with our custom 4-gram LM. As compared to this basline, multistream CNN achieves a relative WER improvement of 14% on test-other, demonstrating its robustness. The lattice rescoring with the TDNN-LSTM language model further reduces the WER by 14% relative, showing the better modeling capability of a neural language model.\\n\\nRegarding self-attentive SRU LMs, we first construct N-best rescoring using the 24-layer BPE SRU model. The language model likelihood is re-estimated by linearly interpolating the TDNN-LSTM and SRU LM. BPE-based LMs can help mitigate out-of-vocabulary issues from word-based models. Also, interpolating LMs with different levels of capacity has been proven to be beneficial to WER reduction in practice. These benefits are presented by the relative WER improvement of 23% on the test sets against the TDNN-LSTM rescoring approach only. When we interpolate the BPE SRU model with the word-level SRU LM, we obtain a slight improvement around 2% relative. Finally, we re-rank the interpolated SRU results by minimizing the expected WER, resulting in further reduction of WER by approximately 1%, also relative.\\n\\nTable 4 compares the WERs between our proposed system and other benchmark systems in the literature. Other than the test-other set, we outperform any other system performances in the group by noticeable margins. In comparison with our previous results , thanks to multistream CNN for acoustic modeling and multiple stages of LM rescoring with powerful self-attentive SRU language models, we improve the relative WERs on test-clean and test-other of 20% and 23%, respectively.\\n\\n                         Dev            Test   \\n  -------------------- ------- ------- ------- -------\\n  2-5                   clean   other   clean   other\\n  TDNN-F + 4-gram       2.75    8.16    2.93    8.17\\n  Multistream CNN       2.62    6.78    2.80    7.06\\n  +4-gram                                      \\n  +TDNN-LSTM LM         2.14    5.82    2.34    6.04\\n  +24-layer SRU         1.56    4.28    1.83    4.57\\n  +Interpolated SRU     1.56    4.25    1.79    4.49\\n  +Expected Word        1.55    4.22    1.75    4.46\\n  Error Minimization                           \\n\\n  : WER (in %) comparison among different setups.\\n\\n         Systems           Dev            Test   \\n  ---------------------- ------- ------- ------- -------\\n           2-5            clean   other   clean   other\\n       Park, et al.         -       -      2.5     5.8\\n     Synnaeve, et al.     2.10    4.79    2.33    5.17\\n   w/o semi-supervision                          \\n     Luscher, et al.       1.9     4.5     2.3     5.0\\n       Wang, et al.         -       -     2.26    4.85\\n       Han, et al.        1.84    5.75    2.20    5.82\\n      Zhang, et al.         -       -      2.0     4.6\\n       Han, et al.          -       -      1.9     4.1\\n        ASAPP-ASR         1.55    4.22    1.75    4.46\\n\\n  : WER (in %) comparison among different systems.\\n\\nConclusions\\n\\nIn this work, we proposed a hybrid ASR system that combines a novel acoustic model architecture, multistream CNN, and an efficient language model, self-attentive SRU. Through the multiple stages of LM rescoring and the expected word error minimization for N-best hypotheses re-ranking, we achieved a new state-of-the-art result on test-clean and competitive performance on test-other in the popular speech benchmark of Librispeech. Multi-resolution processing in a multistream architecture by multistream CNN manifested its robustness on test-other, and self-attentive variant to SRU demonstrated its superiority of modeling power over Transformer.\\n\\nWe will continue on improving the robustness of our acoustic model with efficient usage of a deep CNN architecture and more optimization of data augmentation methods in training. With the promising results presented by the self-attentive SRU in language modeling, we also plan to leverage similar modeling capacity from SRUs in acoustic modeling in the framework of end-to-end ASR.\\n\\n[1] http://openslr.org/11.\\n\\n[2] https://github.com/kaldi-asr/kaldi/tree/master/egs/librispeech/s5.\\n\\n[3] https://github.com/danpovey/pocolm/blob/master/egs/swbd/run.sh.\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_tdms_f1.iloc[0]['prompt'].replace(\n",
    "    '\\nPlease answer a question about this article. If the question is unanswerable, say \\\"unanswerable\\\". What are the values for the following properties to construct a Leaderboard for the model introduced in this article: task, dataset, metric, and score?',\n",
    "    ''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>template</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>92910</td>\n",
       "      <td>92910</td>\n",
       "      <td>92910</td>\n",
       "      <td>92910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>12388</td>\n",
       "      <td>92545</td>\n",
       "      <td>7976</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1704.06326v2.pdf</td>\n",
       "      <td>Title:\\t\\n\\nAbstract:\\t\\n\\n[image]\\n\\nTry to a...</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>drop_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>33072</td>\n",
       "      <td>6198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                             prompt  \\\n",
       "count              92910                                              92910   \n",
       "unique             12388                                              92545   \n",
       "top     1704.06326v2.pdf  Title:\\t\\n\\nAbstract:\\t\\n\\n[image]\\n\\nTry to a...   \n",
       "freq                  14                                                 17   \n",
       "\n",
       "              answer template  \n",
       "count          92910    92910  \n",
       "unique          7976       15  \n",
       "top     unanswerable   drop_7  \n",
       "freq           33072     6198  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_tdms_f1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title:\\tASAPP-ASR: Multistream CNN and Self-Attentive SRU\\nfor SOTA Speech Recognition\\n\\nAbstract:\\tIn this paper we present state-of-the-art (SOTA) performance on the LibriSpeech corpus with two novel neural network architectures, a multistream CNN for acoustic modeling and a self-attentive simple recurrent unit (SRU) for language modeling. In the hybrid ASR framework, the multistream CNN acoustic model processes an input of speech frames in multiple parallel pipelines where each stream has a unique dilation rate for diversity. Trained with the SpecAugment data augmentation method, it achieves relative word error rate (WER) improvements of 4% on test-clean and 14% on test-other. We further improve the performance via N-best rescoring using a 24-layer self-attentive SRU language model, achieving WERs of 1.75% on test-clean and 4.46% on test-other.\\n\\nIndex Terms: speech recognition, state-of-the-art, LibriSpeech, multistream CNN, self-attentive SRU\\n\\nExperimental Setup and Results\\n\\nLibriSpeech\\n\\nWe conduct the experiments on the LibriSpeech corpus , which is a collection of approximately 1,000hr read speech (16kHz) from the audio books that are part of the LibriVox project . The training data is split into 3 partitions of 100hrs, 360hrs, and 500hrs while both of the dev and test data are split into ‘clean’ and ‘other’ categories, where each category contains around 5hrs of audio. The corpus provides extra written texts of 800M words[1] for LMs. We normalize them to correct typos as well as spelling consistencies between British and American English. The same normalization is applied to all the text transcripts of the training, dev and test set to be consistent.\\n\\nAcoustic Models and Non-SRU Language Models\\n\\nWe follow the conventional steps to train hybrid GMM/HMM acoustic models using the default Kaldi recipe for LibriSpeech[2], up to a point where a triphone model is trained with speaker-adaptive training (SAT) with feature-space MLLR (fMLLR) to further refine Gaussian mixture parameters . The alignment of this model is used for neural network model training as the reference label. The multistream CNN AM described in Section 2.1 is trained on the total 960hr training set with the LF-MMI loss, decaying learning rates from 10⁻³ to 10⁻⁵ over the span of 6 epochs. The mini-batch size is 64.\\n\\nTo prepare a lexicon, we select the most frequently used 200K words from the 800M word text and add out-of-vocabulary words to the original lexicon provided by the LibriSpeech corpus with the CMU phoneset, resulting in a 203K word list in total. We train a G2P model using the Sequitur tool to generate pronunciations for the out-of-vocabulary words.\\n\\nWe use the PocoLM tooklit to train n-gram LMs by modifying the default recipe for the Switchboard corpus[3]. A 4-gram LM is trained on the 800M word text as well as the entire text transcripts for the 960hr training data containing around 10M words. This LM is pruned to a 3-gram, which is used for the 1st-pass decoding. The 4-gram LM is used for n-gram LM rescoring.\\n\\nThe TDNN-LSTM language model is trained on the aforementioned combined text, totaling 810M words, with the default Kaldi RNNLM recipe for LibriSpeech. We modify the dimension of embedding to 4,096 to increase the representational power of contexts in word sequences.\\n\\nSelf-Attentive SRU Language Models\\n\\nDataset\\n\\nWe construct our dataset for language modeling by combining the normalized corpus of 800M words with the text transcripts from the 960h training data, for a total of about 810M words. All of our self-attentivce SRU language models are trained at the utterance level (i.e., the model does not leverage any context past sentence boundaries), with a maximum sequence length of 275 tokens. We train a new 10K BPE vocabulary for our model. We limit the maximum sequence length only during training, not when computing dev set perplexity or when rescoring utterances from N-best hypotheses by the acoustic model with the TDNN-LSTM LM. We report perplexity numbers on dev-clean and dev-other, which include start and end of sentence tokens for each utterance.\\n\\nModel configuration\\n\\nAll the self-attentive SRU LMs are trained using a hidden dimension of 2,048 and a projected dimension of 512 for the self-attention layer. We use a learning rate of 2\\u2005⋅\\u200510⁻⁴ and no dropout. Optimization is done with the RAdam optimizer\\xa0 using a cosine annealing learning rate schedule. We train SRU models of 12 and 24 layers, slightly varying architectures. For the 12 layer model, we train across 8 Tesla V100 GPUs with a total batch size of 192 for 10 epochs. We use an embedding size of 2,048 and tie the input and output weights. We use single-headed attention in the self-attentive modules. We train the 24 layer model on 8 Quadro RTX 8000 GPUs with a total batch size of 512 for 12 epochs. We use an embedding size of 512, do not tie weights, and use 2 heads in the self-attentive modules.\\n\\n      Model      Layers   # Params    Dev   \\n  ------------- -------- ---------- ------- -------\\n       4-5                           clean   other\\n   Transformer     12       74M      37.7    39.5\\n       SRU         12       77M      36.2    38.3\\n       SRU         24       139M     34.3    36.8\\n\\n  : BPE-level perplexities on dev-clean and dev-other for 12 layer Transformer, 12 layer SRU and 24 layer SRU LMs. We include start and end of sentence tokens on each utterance.\\n\\nResults\\n\\nTable 1 shows the perplexities obtained on the dev sets. With our 12 and 24-layer models, we achieve dev-clean perplexities of 36.2 and 34.3 respectively. In the first third of training we see the most improvement, with combined dev set perplexities at 40 for the 12-layer model and 37 for the 24-layer model.\\n\\nFor a comparison we also train a 12-layer Transformer model on the 10K BPE vocabulary. We use a model dimension of 768, feedforward dimension of 2,048, and 8 attention heads. These parameters were chosen as they result in a network with a comparable number of parameters to the 12-layer SRU model. All other parameters such as weight tying mirror the 12-layer SRU model. A cosine annealing learning rate schedule is used, with a linear warmup for the first 20,000 steps. By adding a self-attentive module between SRU layers, we are able to achieve better perplexity using a comparable number of parameters.\\n\\nAnalysis\\n\\nWe show that our proposed self-attentive SRU not only improves performance over the Transformer architecture but also converges faster. As shown in Figure 1, the 12-layer Transformer model reaches a perplexity of 40 in under 1.2M steps, while it only takes 622K training steps for the SRU model. This results in a 2 times training speedup. In practice this reduced training time by almost 2 days, allowing for faster iteration and greater exploration.\\n\\nAdditionally, we show that the perplexity improvement achieved by the 12-layer SRU model transfers directly to a WER improvement when used for candidate rescoring. In Table 2 we compare WERs when using both the SRU model and Transformer for the final stage of N-best rescoring, fixing N at 100. In all dev and test sets the 12-layer SRU achieves a lower WER than the Transformer model.\\n\\n[]\\n\\nDev perplexity curves of 12-layer SRU and Transformer models. Vertical lines signify when each model reaches a perplexity of 40. Here perplexity is reported on the combination of dev-clean and dev-other.\\n\\n     Rescoring Model       Dev            Test   \\n  ---------------------- ------- ------- ------- -------\\n           2-5            clean   other   clean   other\\n   12-layer Transformer   1.62    4.41    1.96    4.70\\n       12-layer SRU       1.59    4.38    1.93    4.62\\n\\n  : WER (in %) comparison of 12-layer Transformer and 12-layer SRU for N-best rescoring.\\n\\nResults and Analysis\\n\\nTable 3 shows the WER comparison of different experimental setups for the multistream CNN AM and staged rescoring with various LMs. The setup of TDNN-F + 4-gram is a baseline with the TDNN-F acoustic model of the Kaldi Librispeech recipe rescored with our custom 4-gram LM. As compared to this basline, multistream CNN achieves a relative WER improvement of 14% on test-other, demonstrating its robustness. The lattice rescoring with the TDNN-LSTM language model further reduces the WER by 14% relative, showing the better modeling capability of a neural language model.\\n\\nRegarding self-attentive SRU LMs, we first construct N-best rescoring using the 24-layer BPE SRU model. The language model likelihood is re-estimated by linearly interpolating the TDNN-LSTM and SRU LM. BPE-based LMs can help mitigate out-of-vocabulary issues from word-based models. Also, interpolating LMs with different levels of capacity has been proven to be beneficial to WER reduction in practice. These benefits are presented by the relative WER improvement of 23% on the test sets against the TDNN-LSTM rescoring approach only. When we interpolate the BPE SRU model with the word-level SRU LM, we obtain a slight improvement around 2% relative. Finally, we re-rank the interpolated SRU results by minimizing the expected WER, resulting in further reduction of WER by approximately 1%, also relative.\\n\\nTable 4 compares the WERs between our proposed system and other benchmark systems in the literature. Other than the test-other set, we outperform any other system performances in the group by noticeable margins. In comparison with our previous results , thanks to multistream CNN for acoustic modeling and multiple stages of LM rescoring with powerful self-attentive SRU language models, we improve the relative WERs on test-clean and test-other of 20% and 23%, respectively.\\n\\n                         Dev            Test   \\n  -------------------- ------- ------- ------- -------\\n  2-5                   clean   other   clean   other\\n  TDNN-F + 4-gram       2.75    8.16    2.93    8.17\\n  Multistream CNN       2.62    6.78    2.80    7.06\\n  +4-gram                                      \\n  +TDNN-LSTM LM         2.14    5.82    2.34    6.04\\n  +24-layer SRU         1.56    4.28    1.83    4.57\\n  +Interpolated SRU     1.56    4.25    1.79    4.49\\n  +Expected Word        1.55    4.22    1.75    4.46\\n  Error Minimization                           \\n\\n  : WER (in %) comparison among different setups.\\n\\n         Systems           Dev            Test   \\n  ---------------------- ------- ------- ------- -------\\n           2-5            clean   other   clean   other\\n       Park, et al.         -       -      2.5     5.8\\n     Synnaeve, et al.     2.10    4.79    2.33    5.17\\n   w/o semi-supervision                          \\n     Luscher, et al.       1.9     4.5     2.3     5.0\\n       Wang, et al.         -       -     2.26    4.85\\n       Han, et al.        1.84    5.75    2.20    5.82\\n      Zhang, et al.         -       -      2.0     4.6\\n       Han, et al.          -       -      1.9     4.1\\n        ASAPP-ASR         1.55    4.22    1.75    4.46\\n\\n  : WER (in %) comparison among different systems.\\n\\nConclusions\\n\\nIn this work, we proposed a hybrid ASR system that combines a novel acoustic model architecture, multistream CNN, and an efficient language model, self-attentive SRU. Through the multiple stages of LM rescoring and the expected word error minimization for N-best hypotheses re-ranking, we achieved a new state-of-the-art result on test-clean and competitive performance on test-other in the popular speech benchmark of Librispeech. Multi-resolution processing in a multistream architecture by multistream CNN manifested its robustness on test-other, and self-attentive variant to SRU demonstrated its superiority of modeling power over Transformer.\\n\\nWe will continue on improving the robustness of our acoustic model with efficient usage of a deep CNN architecture and more optimization of data augmentation methods in training. With the promising results presented by the self-attentive SRU in language modeling, we also plan to leverage similar modeling capacity from SRUs in acoustic modeling in the framework of end-to-end ASR.\\n\\n[1] http://openslr.org/11.\\n\\n[2] https://github.com/kaldi-asr/kaldi/tree/master/egs/librispeech/s5.\\n\\n[3] https://github.com/danpovey/pocolm/blob/master/egs/swbd/run.sh.\\n\\n\\nPlease answer a question about this article. If the question is unanswerable, say \"unanswerable\". What are the values for the following properties to construct a Leaderboard for the model introduced in this article: task, dataset, metric, and score?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_tdms_f1.iloc[0][\"prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save = \"/nfs/home/kabenamualus/Research/LLLM-LeaderboardLLM/data_proccess/\"\n",
    "\n",
    "# save to json\n",
    "# with open(f'{path_save}/global_title_to_content.json', 'w') as fp:\n",
    "#     json.dump(global_title_to_content, fp, indent=4)\n",
    "\n",
    "# Opening JSON file\n",
    "with open(f'{path_save}/global_title_to_summ_content.json') as json_file:\n",
    "    global_title_to_content = json.load(json_file)\n",
    "    \n",
    "# with open(f'{path_save}/global_content_to_title.json') as json_file:\n",
    "#     global_content_to_title = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Opening JSON file\n",
    "# with open('data.json') as json_file:\n",
    "#     data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title:\\tASAPP-ASR: Multistream CNN and Self-Attentive SRU\\nfor SOTA Speech Recognition\\n\\nAbstract:\\tIn this paper we present state-of-the-art (SOTA) performance on the LibriSpeech corpus with two novel neural network architectures, a multistream CNN for acoustic modeling and a self-attentive simple recurrent unit (SRU) for language modeling. In the hybrid ASR framework, the multistream CNN acoustic model processes an input of speech frames in multiple parallel pipelines where each stream has a unique dilation rate for diversity. Trained with the SpecAugment data augmentation method, it achieves relative word error rate (WER) improvements of 4% on test-clean and 14% on test-other. We further improve the performance via N-best rescoring using a 24-layer self-attentive SRU language model, achieving WERs of 1.75% on test-clean and 4.46% on test-other.\\n\\nIndex Terms: speech recognition, state-of-the-art, LibriSpeech, multistream CNN, self-attentive SRU\\n\\nExperimental Setup and Results\\n\\nLibriSpeech\\n\\nWe conduct the experiments on the LibriSpeech corpus , which is a collection of approximately 1,000hr read speech (16kHz) from the audio books that are part of the LibriVox project . The training data is split into 3 partitions of 100hrs, 360hrs, and 500hrs while both of the dev and test data are split into ‘clean’ and ‘other’ categories, where each category contains around 5hrs of audio. The corpus provides extra written texts of 800M words[1] for LMs. We normalize them to correct typos as well as spelling consistencies between British and American English. The same normalization is applied to all the text transcripts of the training, dev and test set to be consistent.\\n\\nAcoustic Models and Non-SRU Language Models\\n\\nWe follow the conventional steps to train hybrid GMM/HMM acoustic models using the default Kaldi recipe for LibriSpeech[2], up to a point where a triphone model is trained with speaker-adaptive training (SAT) with feature-space MLLR (fMLLR) to further refine Gaussian mixture parameters . The alignment of this model is used for neural network model training as the reference label. The multistream CNN AM described in Section 2.1 is trained on the total 960hr training set with the LF-MMI loss, decaying learning rates from 10⁻³ to 10⁻⁵ over the span of 6 epochs. The mini-batch size is 64.\\n\\nTo prepare a lexicon, we select the most frequently used 200K words from the 800M word text and add out-of-vocabulary words to the original lexicon provided by the LibriSpeech corpus with the CMU phoneset, resulting in a 203K word list in total. We train a G2P model using the Sequitur tool to generate pronunciations for the out-of-vocabulary words.\\n\\nWe use the PocoLM tooklit to train n-gram LMs by modifying the default recipe for the Switchboard corpus[3]. A 4-gram LM is trained on the 800M word text as well as the entire text transcripts for the 960hr training data containing around 10M words. This LM is pruned to a 3-gram, which is used for the 1st-pass decoding. The 4-gram LM is used for n-gram LM rescoring.\\n\\nThe TDNN-LSTM language model is trained on the aforementioned combined text, totaling 810M words, with the default Kaldi RNNLM recipe for LibriSpeech. We modify the dimension of embedding to 4,096 to increase the representational power of contexts in word sequences.\\n\\nSelf-Attentive SRU Language Models\\n\\nDataset\\n\\nWe construct our dataset for language modeling by combining the normalized corpus of 800M words with the text transcripts from the 960h training data, for a total of about 810M words. All of our self-attentivce SRU language models are trained at the utterance level (i.e., the model does not leverage any context past sentence boundaries), with a maximum sequence length of 275 tokens. We train a new 10K BPE vocabulary for our model. We limit the maximum sequence length only during training, not when computing dev set perplexity or when rescoring utterances from N-best hypotheses by the acoustic model with the TDNN-LSTM LM. We report perplexity numbers on dev-clean and dev-other, which include start and end of sentence tokens for each utterance.\\n\\nModel configuration\\n\\nAll the self-attentive SRU LMs are trained using a hidden dimension of 2,048 and a projected dimension of 512 for the self-attention layer. We use a learning rate of 2\\u2005⋅\\u200510⁻⁴ and no dropout. Optimization is done with the RAdam optimizer\\xa0 using a cosine annealing learning rate schedule. We train SRU models of 12 and 24 layers, slightly varying architectures. For the 12 layer model, we train across 8 Tesla V100 GPUs with a total batch size of 192 for 10 epochs. We use an embedding size of 2,048 and tie the input and output weights. We use single-headed attention in the self-attentive modules. We train the 24 layer model on 8 Quadro RTX 8000 GPUs with a total batch size of 512 for 12 epochs. We use an embedding size of 512, do not tie weights, and use 2 heads in the self-attentive modules.\\n\\n      Model      Layers   # Params    Dev   \\n  ------------- -------- ---------- ------- -------\\n       4-5                           clean   other\\n   Transformer     12       74M      37.7    39.5\\n       SRU         12       77M      36.2    38.3\\n       SRU         24       139M     34.3    36.8\\n\\n  : BPE-level perplexities on dev-clean and dev-other for 12 layer Transformer, 12 layer SRU and 24 layer SRU LMs. We include start and end of sentence tokens on each utterance.\\n\\nResults\\n\\nTable 1 shows the perplexities obtained on the dev sets. With our 12 and 24-layer models, we achieve dev-clean perplexities of 36.2 and 34.3 respectively. In the first third of training we see the most improvement, with combined dev set perplexities at 40 for the 12-layer model and 37 for the 24-layer model.\\n\\nFor a comparison we also train a 12-layer Transformer model on the 10K BPE vocabulary. We use a model dimension of 768, feedforward dimension of 2,048, and 8 attention heads. These parameters were chosen as they result in a network with a comparable number of parameters to the 12-layer SRU model. All other parameters such as weight tying mirror the 12-layer SRU model. A cosine annealing learning rate schedule is used, with a linear warmup for the first 20,000 steps. By adding a self-attentive module between SRU layers, we are able to achieve better perplexity using a comparable number of parameters.\\n\\nAnalysis\\n\\nWe show that our proposed self-attentive SRU not only improves performance over the Transformer architecture but also converges faster. As shown in Figure 1, the 12-layer Transformer model reaches a perplexity of 40 in under 1.2M steps, while it only takes 622K training steps for the SRU model. This results in a 2 times training speedup. In practice this reduced training time by almost 2 days, allowing for faster iteration and greater exploration.\\n\\nAdditionally, we show that the perplexity improvement achieved by the 12-layer SRU model transfers directly to a WER improvement when used for candidate rescoring. In Table 2 we compare WERs when using both the SRU model and Transformer for the final stage of N-best rescoring, fixing N at 100. In all dev and test sets the 12-layer SRU achieves a lower WER than the Transformer model.\\n\\n[]\\n\\nDev perplexity curves of 12-layer SRU and Transformer models. Vertical lines signify when each model reaches a perplexity of 40. Here perplexity is reported on the combination of dev-clean and dev-other.\\n\\n     Rescoring Model       Dev            Test   \\n  ---------------------- ------- ------- ------- -------\\n           2-5            clean   other   clean   other\\n   12-layer Transformer   1.62    4.41    1.96    4.70\\n       12-layer SRU       1.59    4.38    1.93    4.62\\n\\n  : WER (in %) comparison of 12-layer Transformer and 12-layer SRU for N-best rescoring.\\n\\nResults and Analysis\\n\\nTable 3 shows the WER comparison of different experimental setups for the multistream CNN AM and staged rescoring with various LMs. The setup of TDNN-F + 4-gram is a baseline with the TDNN-F acoustic model of the Kaldi Librispeech recipe rescored with our custom 4-gram LM. As compared to this basline, multistream CNN achieves a relative WER improvement of 14% on test-other, demonstrating its robustness. The lattice rescoring with the TDNN-LSTM language model further reduces the WER by 14% relative, showing the better modeling capability of a neural language model.\\n\\nRegarding self-attentive SRU LMs, we first construct N-best rescoring using the 24-layer BPE SRU model. The language model likelihood is re-estimated by linearly interpolating the TDNN-LSTM and SRU LM. BPE-based LMs can help mitigate out-of-vocabulary issues from word-based models. Also, interpolating LMs with different levels of capacity has been proven to be beneficial to WER reduction in practice. These benefits are presented by the relative WER improvement of 23% on the test sets against the TDNN-LSTM rescoring approach only. When we interpolate the BPE SRU model with the word-level SRU LM, we obtain a slight improvement around 2% relative. Finally, we re-rank the interpolated SRU results by minimizing the expected WER, resulting in further reduction of WER by approximately 1%, also relative.\\n\\nTable 4 compares the WERs between our proposed system and other benchmark systems in the literature. Other than the test-other set, we outperform any other system performances in the group by noticeable margins. In comparison with our previous results , thanks to multistream CNN for acoustic modeling and multiple stages of LM rescoring with powerful self-attentive SRU language models, we improve the relative WERs on test-clean and test-other of 20% and 23%, respectively.\\n\\n                         Dev            Test   \\n  -------------------- ------- ------- ------- -------\\n  2-5                   clean   other   clean   other\\n  TDNN-F + 4-gram       2.75    8.16    2.93    8.17\\n  Multistream CNN       2.62    6.78    2.80    7.06\\n  +4-gram                                      \\n  +TDNN-LSTM LM         2.14    5.82    2.34    6.04\\n  +24-layer SRU         1.56    4.28    1.83    4.57\\n  +Interpolated SRU     1.56    4.25    1.79    4.49\\n  +Expected Word        1.55    4.22    1.75    4.46\\n  Error Minimization                           \\n\\n  : WER (in %) comparison among different setups.\\n\\n         Systems           Dev            Test   \\n  ---------------------- ------- ------- ------- -------\\n           2-5            clean   other   clean   other\\n       Park, et al.         -       -      2.5     5.8\\n     Synnaeve, et al.     2.10    4.79    2.33    5.17\\n   w/o semi-supervision                          \\n     Luscher, et al.       1.9     4.5     2.3     5.0\\n       Wang, et al.         -       -     2.26    4.85\\n       Han, et al.        1.84    5.75    2.20    5.82\\n      Zhang, et al.         -       -      2.0     4.6\\n       Han, et al.          -       -      1.9     4.1\\n        ASAPP-ASR         1.55    4.22    1.75    4.46\\n\\n  : WER (in %) comparison among different systems.\\n\\nConclusions\\n\\nIn this work, we proposed a hybrid ASR system that combines a novel acoustic model architecture, multistream CNN, and an efficient language model, self-attentive SRU. Through the multiple stages of LM rescoring and the expected word error minimization for N-best hypotheses re-ranking, we achieved a new state-of-the-art result on test-clean and competitive performance on test-other in the popular speech benchmark of Librispeech. Multi-resolution processing in a multistream architecture by multistream CNN manifested its robustness on test-other, and self-attentive variant to SRU demonstrated its superiority of modeling power over Transformer.\\n\\nWe will continue on improving the robustness of our acoustic model with efficient usage of a deep CNN architecture and more optimization of data augmentation methods in training. With the promising results presented by the self-attentive SRU in language modeling, we also plan to leverage similar modeling capacity from SRUs in acoustic modeling in the framework of end-to-end ASR.\\n\\n[1] http://openslr.org/11.\\n\\n[2] https://github.com/kaldi-asr/kaldi/tree/master/egs/librispeech/s5.\\n\\n[3] https://github.com/danpovey/pocolm/blob/master/egs/swbd/run.sh.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_title_to_content['2005.10469v1.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total available no leaderboard papers: 12164\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12164 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12164/12164 [01:10<00:00, 171.57it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN F1&F2:\\Added No_LB_Papers: 0\n",
      "Missed Parsing: 12164\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "papers_in_training = []\n",
    "no_leaderboard_papers = []\n",
    "dict_title_docteat = {}\n",
    "\n",
    "missed_parsing = 0\n",
    "\n",
    "i = 0\n",
    "\n",
    "print(f\"Total available no leaderboard papers: {len(os.listdir(long_txt_path))}\\n\\n\")\n",
    "\n",
    "\n",
    "for file_id_sum_txt in tqdm(os.listdir(long_txt_path), total = len(os.listdir(long_txt_path))):\n",
    "    \n",
    "    file_id = file_id_sum_txt.rsplit(\"_\", 1)[0]  \n",
    "    \n",
    "    try:\n",
    "        with open(f'{long_txt_path}/{file_id}_summarised.txt', 'r') as file:\n",
    "            # Read the file\n",
    "            data = file.read()\n",
    "        \n",
    "    except :\n",
    "        missed_parsing += 1\n",
    "        continue \n",
    "\n",
    "    dict_title_docteat[data] = data\n",
    "\n",
    "print(f\"TRAIN F1&F2:\\Added No_LB_Papers: {i}\\nMissed Parsing: {missed_parsing}\\n\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_pd.title.unique())\n",
    "records_train_f1 = df_train_tdms_f1.to_dict(\"records\")\n",
    "records_dev_f1 = df_dev_tdms_f1.to_dict(\"records\")\n",
    "records_zeroshot_f1 = df_zeroshot_tdms_f1.to_dict(\"records\")\n",
    "\n",
    "records_train_f2 = df_train_tdms_f2.to_dict(\"records\")\n",
    "records_dev_f2 = df_dev_tdms_f2.to_dict(\"records\")\n",
    "\n",
    "records_docteat = df_docteat_full.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_parsing = 0\n",
    "missed_short_context = 0\n",
    "copied = 0\n",
    "dict_title_docteat = {}\n",
    "\n",
    "for i, row in tqdm(enumerate(records_train_f1), total = len(records_train_f1)):\n",
    "    \n",
    "    dict_title_docteat[row['title']] = row['content']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41340.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_parsing = 0\n",
    "missed_short_context = 0\n",
    "copied = 0\n",
    "for i, row in tqdm(enumerate(records_train_f1), total = len(records_train_f1)):\n",
    "    title_id = row['title'].split(\".pdf\")[0]\n",
    "    if row['title'] in title_to_content[\"train_f1\"]:\n",
    "        continue \n",
    "    else:\n",
    "        try:\n",
    "            with open(f'{arxiv_leaderboard_full_txt}/{title_id}_summarised.txt', 'r') as file:\n",
    "                # Read the file\n",
    "                data = file.read()\n",
    "                \n",
    "        except :\n",
    "            missed_parsing += 1\n",
    "            continue\n",
    "\n",
    "        if len(data.split()) < 10:\n",
    "            missed_short_context += 1\n",
    "            continue\n",
    "        else:\n",
    "            title_to_content[\"train_f1\"][row['title']] = data\n",
    "            global_title_to_content[row['title']] = data\n",
    "            copied += 1\n",
    "        # title_to_content[\"train_f1\"][row['title']] = row['Context'] if len(data.split()) < 100 else data\n",
    "        # title_to_content[\"train_f1\"][row['title']] = row['Context']\n",
    "\n",
    "print(f\"TRAIN F1:\\nCopied: {copied}\\nMissed Parsing: {missed_parsing}\\\n",
    "\\nMissed Short Context: {missed_short_context}\\nAll items: {len(records_train_f1)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17640.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(17641+17640)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset parquet/default to /nfs/home/kabenamualus/.cache/huggingface/datasets/parquet/default-29eb339c6e04d3c3/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef4b9d331794838ac7b4fc25e653926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38893c2dd426443cb5e7ffb271b5d16a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eadec0e8cac442f8a3c5df41112353e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /nfs/home/kabenamualus/.cache/huggingface/datasets/parquet/default-29eb339c6e04d3c3/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset parquet/default to /nfs/home/kabenamualus/.cache/huggingface/datasets/parquet/default-7b5bbfef9bd9a971/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b3b5da9ffb405388eed52328ea7379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5469412a1de4c09a138171a63cf0d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb21e1276f94682800cd97b8633a789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /nfs/home/kabenamualus/.cache/huggingface/datasets/parquet/default-7b5bbfef9bd9a971/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset parquet/default to /nfs/home/kabenamualus/.cache/huggingface/datasets/parquet/default-e54272126e612309/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc446e2ce07b437ab4755333d73790b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6102dbfa0f4233826dcfb38d776e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e502672be0247b2b0f365b250136797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /nfs/home/kabenamualus/.cache/huggingface/datasets/parquet/default-e54272126e612309/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset parquet/default to /nfs/home/kabenamualus/.cache/huggingface/datasets/parquet/default-d686366d5bbf6eda/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbd2b0746924f43a7081f4692924dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90b0772066840c18ab9ee2c1173d919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9378cc6b827b47ada785b7541e931b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /nfs/home/kabenamualus/.cache/huggingface/datasets/parquet/default-d686366d5bbf6eda/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset parquet/default to /nfs/home/kabenamualus/.cache/huggingface/datasets/parquet/default-ae64c39fbf58a572/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b150c820e24bad90a13bc155bc8ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3510401ec6ec4e64adde8de89bfa5c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e66e6ed62c4c2c95ea8a0ab4de7f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /nfs/home/kabenamualus/.cache/huggingface/datasets/parquet/default-ae64c39fbf58a572/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7. Subsequent calls will reuse this data.\n",
      "DatasetDict({\n",
      "    fold1: DatasetDict({\n",
      "        train: Dataset({\n",
      "            features: ['prompt', 'answer', 'template'],\n",
      "            num_rows: 92910\n",
      "        })\n",
      "        validation: Dataset({\n",
      "            features: ['prompt', 'answer', 'template'],\n",
      "            num_rows: 12315\n",
      "        })\n",
      "        zeroshot: Dataset({\n",
      "            features: ['prompt', 'answer', 'template'],\n",
      "            num_rows: 9000\n",
      "        })\n",
      "    })\n",
      "    fold2: DatasetDict({\n",
      "        train: Dataset({\n",
      "            features: ['prompt', 'answer', 'template'],\n",
      "            num_rows: 92864\n",
      "        })\n",
      "        validation: Dataset({\n",
      "            features: ['prompt', 'answer', 'template'],\n",
      "            num_rows: 12360\n",
      "        })\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf33817b124e4af193cfe8c5d6a7babb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/92910 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260a5f746f5b46e3bff09f1a00b4b3ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/12315 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35670def17a48898fa814c95466eeca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/9000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37c2908934b458580ee2c5ddedcf02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/92864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25fe5d5799f47598aade3064a01abda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/12360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_tdms_f1_50_percent.to_parquet('../data/df_train_tdms_augmented_summarized_with_id_f1_50_percent.parquet')\n",
    "df_dev_tdms_f1_50_percent.to_parquet('../data/df_dev_tdms_augmented_summarized_with_id_f1_50_percent.parquet')\n",
    "df_zeroshot_tdms_f1_50_percent.to_parquet('../data/df_zeroshot_tdms_augmented_summarized_with_id_f1_50_percent.parquet')\n",
    "\n",
    "df_train_tdms_f2_50_percent.to_parquet('../data/df_train_tdms_augmented_summarized_with_id_f2_50_percent.parquet')\n",
    "df_dev_tdms_f2_50_percent.to_parquet('../data/df_dev_tdms_augmented_summarized_with_id_f2_50_percent.parquet')\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'fold1': DatasetDict({\n",
    "        \"train\": Dataset.from_parquet('../data/df_train_tdms_augmented_summarized_with_id_f1_50_percent.parquet'),\n",
    "        \"validation\": Dataset.from_parquet('../data/df_dev_tdms_augmented_summarized_with_id_f1_50_percent.parquet'),\n",
    "        \"zeroshot\": Dataset.from_parquet('../data/df_zeroshot_tdms_augmented_summarized_with_id_f1_50_percent.parquet')\n",
    "    }),\n",
    "    'fold2': DatasetDict({\n",
    "        \"train\": Dataset.from_parquet('../data/df_train_tdms_augmented_summarized_with_id_f2_50_percent.parquet'),\n",
    "        \"validation\": Dataset.from_parquet('../data/df_dev_tdms_augmented_summarized_with_id_f2_50_percent.parquet')\n",
    "    })\n",
    "})\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "dataset.save_to_disk(\"../data/LLLM_AUGMENTED_SUMMARIZED_ZEROSHOT_TDMS_50_PERCENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "036d1c9003ee43acb0c2b89783ef7317": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04be517c49014350a3a4aed13af1beb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "06c39c7b19ff4102a059335937096a77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07e9a50ed7014724aaf6f083e481cc01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aaa4609ff63a4451a2f27d87265b3f71",
      "placeholder": "​",
      "style": "IPY_MODEL_e8fcd026196044a08250eeb8f0c9bdd8",
      "value": " 792k/792k [00:01&lt;00:00, 537kB/s]"
     }
    },
    "080d2b5824c340848a99a988f65199bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b95b3978ff674a119683e3ac0fe936e9",
       "IPY_MODEL_dfae349d2c6e4efb93933fc4c011fe97",
       "IPY_MODEL_21a2c896f1c24781b4fe5834cea2454c"
      ],
      "layout": "IPY_MODEL_ba52a3af729042e9b11f1d4e22a553eb"
     }
    },
    "0effbee2d34943fc8d6d0d3a265d0766": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0f2ce18b656a4e7ead8774f9c28b4eda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "1144779119e843109365495f972af363": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68df245747594d27b8db61a63ea30b36",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4ea5fb72af6e46438af4ad47cbbd32d2",
      "value": 2
     }
    },
    "13466f14b2484f7dbfd7ffe2ecc395f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "13f3d839ed0249c082da5c8da1ebd386": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee070df2cc9b42d6891e5ae557040066",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a926a4c6b7f345b2a021410743ed5d53",
      "value": 500
     }
    },
    "1572ca2178b64d0d9accd4c7620d0f96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16f0f99dbcfa4ff8b459aa5d3d9c74cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "170cc57e9f92469597b6aab8962a8ce3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c607df922234a20b8f72f92b965c452": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e915a28fc764077977f06cf12c95c04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21a2c896f1c24781b4fe5834cea2454c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b410e5b0ca02405f9d71072f1e34b2ba",
      "placeholder": "​",
      "style": "IPY_MODEL_44389af5674642c1891cc2bf208838a6",
      "value": " 242M/242M [00:03&lt;00:00, 72.8MB/s]"
     }
    },
    "22702932b5dd4bdca2ca98bd75b20a93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23fc564de44144718f5fd9bbe921ae80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26ffcb55db4149d38c34570982fa0fca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2921977fec8c4f54b727f6aa12334d09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8fb7ca7667254da58ef251e6c2e4483e",
      "placeholder": "​",
      "style": "IPY_MODEL_91f420fdfedb464a8455c52b05bbdaad",
      "value": "Downloading: 100%"
     }
    },
    "29edae08655f4c478cddb3e5441e8ae6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40915c810d8e41f6a7bcc8faa84ba0bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7feb6429c4e24fd89aab0a3b0efd38eb",
      "placeholder": "​",
      "style": "IPY_MODEL_e88c4810f71346019c6d9765cacc3284",
      "value": " 500/500 [00:27&lt;00:00, 18.35it/s]"
     }
    },
    "44389af5674642c1891cc2bf208838a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45746813cd3c4d82ada51bf58274a791": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b42a824910bf495289c9f56f241fc6f6",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_604014d142594f4f87ce70e164d94a14",
      "value": 500
     }
    },
    "4c02d0ce16fe4c6187a2c8b952e8419f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22702932b5dd4bdca2ca98bd75b20a93",
      "placeholder": "​",
      "style": "IPY_MODEL_170cc57e9f92469597b6aab8962a8ce3",
      "value": "Downloading: 100%"
     }
    },
    "4ea5fb72af6e46438af4ad47cbbd32d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4f45cc2640f44395a635a928f6d2f4f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ec023301cdad42cdabc32be9ee003f2a",
       "IPY_MODEL_cb9a3ee490e248398094c6789cc8526e",
       "IPY_MODEL_40915c810d8e41f6a7bcc8faa84ba0bb"
      ],
      "layout": "IPY_MODEL_96e050ff888943fc90182209e4d72227"
     }
    },
    "5f5740fe5a3e45289881a5ed5a498764": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "604014d142594f4f87ce70e164d94a14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6519d08cb83a4e7386bdda75f8f16861": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "68df245747594d27b8db61a63ea30b36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c2c9da14016449a8c13e08b395f7b23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6cd3ede915c84c629bf46d234388b02c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbad20d361c6425cbb716354a9e8d328",
      "placeholder": "​",
      "style": "IPY_MODEL_96a9941107bd4e9b984755365e80df22",
      "value": " 500/500 [00:27&lt;00:00, 18.43it/s]"
     }
    },
    "6f01127a146d443a973c0c3674663559": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc6fda81438846b8bd09a059bc0b5553",
       "IPY_MODEL_45746813cd3c4d82ada51bf58274a791",
       "IPY_MODEL_6cd3ede915c84c629bf46d234388b02c"
      ],
      "layout": "IPY_MODEL_13466f14b2484f7dbfd7ffe2ecc395f7"
     }
    },
    "71b01ab113c341fc8e4c8a2e36f336f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e915a28fc764077977f06cf12c95c04",
      "placeholder": "​",
      "style": "IPY_MODEL_bffcb591f4d74ebab31550f134f89dca",
      "value": "Validation DataLoader 0: 100%"
     }
    },
    "74f7576971d74113aa0605f41eb5fb89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c69b41b3fb8748cea2e7770562b47ce3",
      "placeholder": "​",
      "style": "IPY_MODEL_a04320425bd94c79a497cc7dd9b144ce",
      "value": " 1.21k/1.21k [00:00&lt;00:00, 69.2kB/s]"
     }
    },
    "7c90ba46512d4a94a1971f5f4b4d97d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7feb6429c4e24fd89aab0a3b0efd38eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "853f16aaaa5c4d13a67b143f2e946c3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4a7c18179414629ab20376d4180a8a7",
      "placeholder": "​",
      "style": "IPY_MODEL_d5e1a9a72304460a9021598550913edc",
      "value": " 1000/1000 [02:05&lt;00:00,  7.96it/s, loss=1.16, v_num=2]"
     }
    },
    "8a1d7051e6ce4cbe8ad268b12751f4ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4c02d0ce16fe4c6187a2c8b952e8419f",
       "IPY_MODEL_cffb3f880b7f45719ad19c6fbb082948",
       "IPY_MODEL_07e9a50ed7014724aaf6f083e481cc01"
      ],
      "layout": "IPY_MODEL_23fc564de44144718f5fd9bbe921ae80"
     }
    },
    "8fb7ca7667254da58ef251e6c2e4483e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91f420fdfedb464a8455c52b05bbdaad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93adec39ba514f24a582ddbd529e01a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "96a9941107bd4e9b984755365e80df22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96e050ff888943fc90182209e4d72227": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "9ab910f3fc8540f591c0db3dffc74cb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb3484e0e3d14bd7b8b7b0163fc6c81a",
      "placeholder": "​",
      "style": "IPY_MODEL_6519d08cb83a4e7386bdda75f8f16861",
      "value": " 2/2 [00:00&lt;00:00, 23.71it/s]"
     }
    },
    "9cfda34969e044acb3368d547caf95ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2b40eec0a5d4ec189a327d95a1cfd90",
      "placeholder": "​",
      "style": "IPY_MODEL_f9fe48215ce14b91b0a57cd3c7096334",
      "value": "Sanity Checking DataLoader 0: 100%"
     }
    },
    "9d8a386189cc4a9c81b836fb41fa4f64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29edae08655f4c478cddb3e5441e8ae6",
      "placeholder": "​",
      "style": "IPY_MODEL_de53a4b226e541d28da4547ac58579ff",
      "value": "Epoch 2: 100%"
     }
    },
    "9d96616dfac14f2d8535a07cc5e13711": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_71b01ab113c341fc8e4c8a2e36f336f9",
       "IPY_MODEL_13f3d839ed0249c082da5c8da1ebd386",
       "IPY_MODEL_ab368c585dfa4b9ab4f97c7cd9d52f77"
      ],
      "layout": "IPY_MODEL_fdda03cbcaae4da1815b38ba5d40a7f0"
     }
    },
    "a04320425bd94c79a497cc7dd9b144ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a926a4c6b7f345b2a021410743ed5d53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aa8d3f0d5edc43519b03b9360708f8b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aaa4609ff63a4451a2f27d87265b3f71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab368c585dfa4b9ab4f97c7cd9d52f77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1572ca2178b64d0d9accd4c7620d0f96",
      "placeholder": "​",
      "style": "IPY_MODEL_c5ae98203edb4bdb83443d3f05b08247",
      "value": " 500/500 [00:27&lt;00:00, 18.34it/s]"
     }
    },
    "ae41b724aa4f469f8c408848d2a9de1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fccbbd51784e428697cd8a47d9b94317",
      "max": 1206,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_04be517c49014350a3a4aed13af1beb4",
      "value": 1206
     }
    },
    "afa135917c1f4273bfdcc9e6f8c56683": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "b410e5b0ca02405f9d71072f1e34b2ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b42a824910bf495289c9f56f241fc6f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b572e3cd384c46499d0e8e4f7d52123a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b95b3978ff674a119683e3ac0fe936e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eef3c52f6b534523870e3ea61223014b",
      "placeholder": "​",
      "style": "IPY_MODEL_1c607df922234a20b8f72f92b965c452",
      "value": "Downloading: 100%"
     }
    },
    "ba52a3af729042e9b11f1d4e22a553eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb3484e0e3d14bd7b8b7b0163fc6c81a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bffcb591f4d74ebab31550f134f89dca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2b40eec0a5d4ec189a327d95a1cfd90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5ae98203edb4bdb83443d3f05b08247": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c69b41b3fb8748cea2e7770562b47ce3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6ccf24b960c4b25a59265c68780a0e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d8a386189cc4a9c81b836fb41fa4f64",
       "IPY_MODEL_e40763a82dc34304aca5e042c9e77375",
       "IPY_MODEL_853f16aaaa5c4d13a67b143f2e946c3a"
      ],
      "layout": "IPY_MODEL_0f2ce18b656a4e7ead8774f9c28b4eda"
     }
    },
    "cb9a3ee490e248398094c6789cc8526e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b572e3cd384c46499d0e8e4f7d52123a",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_93adec39ba514f24a582ddbd529e01a0",
      "value": 500
     }
    },
    "cbad20d361c6425cbb716354a9e8d328": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cce9d70e2dc94fc398e63efce16ce4ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9cfda34969e044acb3368d547caf95ef",
       "IPY_MODEL_1144779119e843109365495f972af363",
       "IPY_MODEL_9ab910f3fc8540f591c0db3dffc74cb5"
      ],
      "layout": "IPY_MODEL_afa135917c1f4273bfdcc9e6f8c56683"
     }
    },
    "cffb3f880b7f45719ad19c6fbb082948": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06c39c7b19ff4102a059335937096a77",
      "max": 791656,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_26ffcb55db4149d38c34570982fa0fca",
      "value": 791656
     }
    },
    "d5e1a9a72304460a9021598550913edc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da395e550e3f40379416bc4b2ae0acd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "de53a4b226e541d28da4547ac58579ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dfae349d2c6e4efb93933fc4c011fe97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa8d3f0d5edc43519b03b9360708f8b2",
      "max": 242065649,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_da395e550e3f40379416bc4b2ae0acd0",
      "value": 242065649
     }
    },
    "e340d5c2a56247918e94384810ea21d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e40763a82dc34304aca5e042c9e77375": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f5740fe5a3e45289881a5ed5a498764",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0effbee2d34943fc8d6d0d3a265d0766",
      "value": 1000
     }
    },
    "e88c4810f71346019c6d9765cacc3284": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8fcd026196044a08250eeb8f0c9bdd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ebf189ef3899443fb90e40e5abd4f088": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2921977fec8c4f54b727f6aa12334d09",
       "IPY_MODEL_ae41b724aa4f469f8c408848d2a9de1f",
       "IPY_MODEL_74f7576971d74113aa0605f41eb5fb89"
      ],
      "layout": "IPY_MODEL_7c90ba46512d4a94a1971f5f4b4d97d8"
     }
    },
    "ec023301cdad42cdabc32be9ee003f2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e340d5c2a56247918e94384810ea21d9",
      "placeholder": "​",
      "style": "IPY_MODEL_6c2c9da14016449a8c13e08b395f7b23",
      "value": "Validation DataLoader 0: 100%"
     }
    },
    "ee070df2cc9b42d6891e5ae557040066": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eef3c52f6b534523870e3ea61223014b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4a7c18179414629ab20376d4180a8a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9fe48215ce14b91b0a57cd3c7096334": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc6fda81438846b8bd09a059bc0b5553": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_036d1c9003ee43acb0c2b89783ef7317",
      "placeholder": "​",
      "style": "IPY_MODEL_16f0f99dbcfa4ff8b459aa5d3d9c74cd",
      "value": "Validation DataLoader 0: 100%"
     }
    },
    "fccbbd51784e428697cd8a47d9b94317": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdda03cbcaae4da1815b38ba5d40a7f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
